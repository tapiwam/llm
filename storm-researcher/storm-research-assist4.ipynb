{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b912966-4dce-4685-a5b2-a39c5229a0f1",
   "metadata": {},
   "source": [
    "# Storm Research Assistant\n",
    "\n",
    "Reference\n",
    "https://github.com/langchain-ai/langgraph/blob/main/examples/storm/storm.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32108c2-977f-450d-82cb-90aa21f09171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "from storm import *\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "fast_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "# long_context_llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "long_context_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# haiku model\n",
    "# haiku_model_name = \"claude-3-haiku-20240307\"\n",
    "# fast_llm = ChatAnthropic(model_name=haiku_model_name)\n",
    "# long_context_llm = ChatAnthropic(model_name=haiku_model_name)\n",
    "\n",
    "\n",
    "embeddings = get_gpt4all_embeddings()\n",
    "\n",
    "vectorstore_dir = \"./data/storm/vectorstore/\"\n",
    "vectorstore = Chroma(persist_directory=vectorstore_dir, embedding_function=embeddings)\n",
    "\n",
    "interview_config = InterviewConfig(long_llm=long_context_llm, \n",
    "                                   fast_llm=fast_llm, \n",
    "                                   max_conversations=3, \n",
    "                                   max_reference_length=10000,\n",
    "                                   tags_to_extract=[ \"p\", \"h1\", \"h2\", \"h3\"],\n",
    "                                   embeddings=embeddings,\n",
    "                                   vectorstore=vectorstore,\n",
    "                                   vectorstore_dir=vectorstore_dir,\n",
    "                                   runnable_config=RunnableConfig()\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8209e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs topic as input - {\"topic\": \"\"}\n",
    "outline = get_chain_outline(interview_config.fast_llm)\n",
    "\n",
    "# Needs topic as input - {\"topic\": \"\"}\n",
    "expand_chain = get_chain_expand_related_topics(fast_llm)\n",
    "\n",
    "\n",
    "gen_perspectives_chain = get_chain_perspective_generator(fast_llm)\n",
    "\n",
    "# Need messages as input - {\"messages\": []}\n",
    "gen_queries_chain = get_chain_queries(fast_llm)\n",
    "gen_answer_chain = get_chain_answer(fast_llm)\n",
    "\n",
    "example_topic = \"Increase development productivity by using Docker compose and local docker labs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22285165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:23,936 [MainThread  ] [INFO ]  Generating question for JohnDoe\n",
      "2024-04-23 12:03:24,781 [MainThread  ] [INFO ]  Generated question for JohnDoe: What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?\n",
      "2024-04-23 12:03:24,818 [MainThread  ] [INFO ]  START - Generate answer for [JohnDoe] - Question: [What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_question\n",
      "Processing step: ask_question\n",
      "--  [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-tur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:25,768 [MainThread  ] [INFO ]  Got 1 search engine queries for [JohnDoe] -\n",
      "\t ['recent advancements in software development that have significantly impacted industry efficiency and productivity']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [recent advancements in software development that have significantly impacted industry efficiency and productivity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:26,970 [MainThread  ] [INFO ]  Search result: {'ids': [], 'embeddings': None, 'metadatas': [], 'documents': [], 'uris': None, 'data': None}\n",
      "2024-04-23 12:03:26,971 [MainThread  ] [INFO ]  Storing doc: https://www.simform.com/blog/software-development-trends-2024/ with query: recent advancements in software development that have significantly impacted industry efficiency and productivity\n",
      "2024-04-23 12:03:27,080 [MainThread  ] [INFO ]  Done storing doc: https://www.simform.com/blog/software-development-trends-2024/\n",
      "2024-04-23 12:03:27,080 [MainThread  ] [INFO ]  Data stored in vector store. Chunks: 1\n",
      "2024-04-23 12:03:27,081 [MainThread  ] [INFO ]  Got 1 search engine results for [JohnDoe] - stored_chunks=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [recent advancements in software development that have significantly impacted industry efficiency and productivity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:32,442 [MainThread  ] [INFO ]  Got answer from QA chain for [JohnDoe]: \n",
      "\tQuestion: What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity? \n",
      "\tRaw Answer: {'context': [Document(page_content='Over the years, we have witnessed many advancements in tools and methodologies in software development aimed at enhancing productivity, streamlining processes and accelerating development cycles.', metadata={'query': 'recent advancements in software development that have significantly impacted industry efficiency and productivity', 'source': 'https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2024/04/17/unlocking-the-future-how-generative-ai-is-revolutionizing-software-engineering/'}), Document(page_content='Leveraging the Latest Software Development Trends. In 2024, several types of emerging technology are poised to have a massive impact on the software development industry. By staying ahead of the curve', metadata={'query': 'how is software development industry evolving', 'source': 'https://www.stackspot.com/en/blog/software-development-industry'}), Document(page_content='The Current State of the Software Development Industry. The technology sector in 2023 was dominated by a few prominent software industry trends that highlighted massive shifts in this space. For', metadata={'query': 'current software development industry trends', 'source': 'https://clickup.com/blog/software-engineering-trends/'}), Document(page_content='software development together posted nearly one million jobs between 2018 and 2022. Next-generation software development saw the most significant growth in number of jobs ...', metadata={'query': 'current software development industry trends', 'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech'})], 'question': 'What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', 'answer': 'Some recent advancements in software development that have significantly impacted the industry include leveraging emerging technologies, staying ahead of the curve, and focusing on next-generation software development trends. These advancements have aimed to enhance productivity, streamline processes, and accelerate development cycles.'}\n",
      "2024-04-23 12:03:32,443 [MainThread  ] [INFO ]  Generating final answer for [JohnDoe] - \n",
      "\t {'context': [Document(page_content='Over the years, we have witnessed many advancements in tools and methodologies in software development aimed at enhancing productivity, streamlining processes and accelerating development cycles.', metadata={'query': 'recent advancements in software development that have significantly impacted industry efficiency and productivity', 'source': 'https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2024/04/17/unlocking-the-future-how-generative-ai-is-revolutionizing-software-engineering/'}), Document(page_content='Leveraging the Latest Software Development Trends. In 2024, several types of emerging technology are poised to have a massive impact on the software development industry. By staying ahead of the curve', metadata={'query': 'how is software development industry evolving', 'source': 'https://www.stackspot.com/en/blog/software-development-industry'}), Document(page_content='The Current State of the Software Development Industry. The technology sector in 2023 was dominated by a few prominent software industry trends that highlighted massive shifts in this space. For', metadata={'query': 'current software development industry trends', 'source': 'https://clickup.com/blog/software-engineering-trends/'}), Document(page_content='software development together posted nearly one million jobs between 2018 and 2022. Next-generation software development saw the most significant growth in number of jobs ...', metadata={'query': 'current software development industry trends', 'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech'})], 'question': 'What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', 'answer': 'Some recent advancements in software development that have significantly impacted the industry include leveraging emerging technologies, staying ahead of the curve, and focusing on next-generation software development trends. These advancements have aimed to enhance productivity, streamline processes, and accelerate development cycles.'}\n",
      "2024-04-23 12:03:36,049 [MainThread  ] [INFO ]  Genreted final answer answer='Some recent advancements in software development that have significantly impacted the industry include leveraging emerging technologies, staying ahead of the curve, and focusing on next-generation software development trends. These advancements have aimed to enhance productivity, streamline processes, and accelerate development cycles.' cited_urls=['https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2024/04/17/unlocking-the-future-how-generative-ai-is-revolutionizing-software-engineering/', 'https://www.stackspot.com/en/blog/software-development-industry', 'https://clickup.com/blog/software-engineering-trends/', 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech'] for [JohnDoe] - \n",
      "\t Some recent advancements in software development that have significantly impacted the industry include leveraging emerging technologies, staying ahead of the curve, and focusing on next-generation software development trends. These advancements have aimed to enhance productivity, streamline processes, and accelerate development cycles.\n",
      "\n",
      "Citations:\n",
      "\n",
      "[1]: https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2024/04/17/unlocking-the-future-how-generative-ai-is-revolutionizing-software-engineering/\n",
      "[2]: https://www.stackspot.com/en/blog/software-development-industry\n",
      "[3]: https://clickup.com/blog/software-engineering-trends/\n",
      "[4]: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech\n",
      "2024-04-23 12:03:36,050 [MainThread  ] [INFO ]  END - generate answer for [JohnDoe]\n",
      "2024-04-23 12:03:36,069 [MainThread  ] [INFO ]  Generating question for JohnDoe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_question\n",
      "Processing step: answer_question\n",
      "--  [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-tur\n",
      "InterviewState.from_dict: data is an instance of dict\n",
      "Routing messages for [JohnDoe]\n",
      "Continue asking question for [JohnDoe] as this is not the last end of the conversation - ResponseCount: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:37,028 [MainThread  ] [INFO ]  Generated question for JohnDoe: What are the latest trends in software development methodologies that companies are utilizing in the current industry landscape?\n",
      "2024-04-23 12:03:37,056 [MainThread  ] [INFO ]  START - Generate answer for [JohnDoe] - Question: [What are the latest trends in software development methodologies that companies are utilizing in the current industry landscape?]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_question\n",
      "Processing step: ask_question\n",
      "--  [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-tur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:38,578 [MainThread  ] [INFO ]  Got 4 search engine queries for [JohnDoe] -\n",
      "\t ['latest trends in software development methodologies in 2021', 'popular software development methodologies used by companies', 'how companies are adapting agile methodologies', 'impact of DevOps on software development processes']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [latest trends in software development methodologies in 2021]\n",
      "Got search engine results: 5 for [latest trends in software development methodologies in 2021]\n",
      "Searching DuckDuckGo for [popular software development methodologies used by companies]\n",
      "Searching DuckDuckGo for [how companies are adapting agile methodologies]\n",
      "Got search engine results: 5 for [how companies are adapting agile methodologies]\n",
      "Searching DuckDuckGo for [impact of DevOps on software development processes]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:41,754 [MainThread  ] [ERROR]  Error running search engine for [JohnDoe]: popular software development methodologies used by companies - https://duckduckgo.com RequestsError: Failed to perform, curl: (7) Failed to connect to duckduckgo.com port 443 after 1 ms: Couldn't connect to server. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n",
      "2024-04-23 12:03:41,756 [MainThread  ] [INFO ]  Search result: {'ids': ['191faabc-03ef-4461-9d08-c82539bf9462', '9c7a63bc-aa69-40ff-9c3d-81c8f0cf4cf7'], 'embeddings': None, 'metadatas': [{'query': 'latest trends in software development 2021', 'source': 'https://learn.g2.com/software-development-statistics'}, {'query': 'latest trends in software development 2021', 'source': 'https://learn.g2.com/software-development-statistics'}], 'documents': ['Software marketing is expected to receive 28% of all tech investment dollars. The shift to cloud services will be huge, reaching $55.9 trillion by 2030. This trend is already affecting the software', 'affecting the software industry, as the cloud services market grew by over $1.3 trillion in 2022. StackOverflow is the most popular online community for software developers.'], 'uris': None, 'data': None}\n",
      "2024-04-23 12:03:41,757 [MainThread  ] [INFO ]  Vectorstore already has doc: {'source': 'https://learn.g2.com/software-development-statistics'} with ids: ['191faabc-03ef-4461-9d08-c82539bf9462', '9c7a63bc-aa69-40ff-9c3d-81c8f0cf4cf7']\n",
      "2024-04-23 12:03:41,758 [MainThread  ] [INFO ]  Search result: {'ids': [], 'embeddings': None, 'metadatas': [], 'documents': [], 'uris': None, 'data': None}\n",
      "2024-04-23 12:03:41,759 [MainThread  ] [INFO ]  Storing doc: https://medium.com/selleo/the-future-of-scrum-trends-and-innovations-in-agile-project-management-53d9f2a17062 with query: how companies are adapting agile methodologies\n",
      "2024-04-23 12:03:41,879 [MainThread  ] [INFO ]  Done storing doc: https://medium.com/selleo/the-future-of-scrum-trends-and-innovations-in-agile-project-management-53d9f2a17062\n",
      "2024-04-23 12:03:41,879 [MainThread  ] [INFO ]  Search result: {'ids': [], 'embeddings': None, 'metadatas': [], 'documents': [], 'uris': None, 'data': None}\n",
      "2024-04-23 12:03:41,880 [MainThread  ] [INFO ]  Storing doc: https://www.sophisticatedcloud.com/all-blogs/the-rise-of-devops-streamlining-software-development-processes with query: impact of DevOps on software development processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [impact of DevOps on software development processes]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:41,973 [MainThread  ] [INFO ]  Done storing doc: https://www.sophisticatedcloud.com/all-blogs/the-rise-of-devops-streamlining-software-development-processes\n",
      "2024-04-23 12:03:41,974 [MainThread  ] [INFO ]  Data stored in vector store. Chunks: 3\n",
      "2024-04-23 12:03:41,975 [MainThread  ] [INFO ]  Got 3 search engine results for [JohnDoe] - stored_chunks=16\n",
      "2024-04-23 12:03:46,768 [MainThread  ] [INFO ]  Got answer from QA chain for [JohnDoe]: \n",
      "\tQuestion: What are the latest trends in software development methodologies that companies are utilizing in the current industry landscape? \n",
      "\tRaw Answer: {'context': [Document(page_content='17 Key Software Development Trends. As we make our way through 2024, the software development industry is rapidly evolving with new technologies, methodologies, and a growing demand for innovative', metadata={'query': 'how is software development industry evolving', 'source': 'https://spdload.com/blog/software-development-trends/'}), Document(page_content='17 Key Software Development Trends. Updated on 1 Apr 2024. 9 min. As we make our way through 2024, the software development industry is rapidly evolving with new technologies, methodologies, and a', metadata={'query': 'current software development industry trends', 'source': 'https://spdload.com/blog/software-development-trends/'}), Document(page_content='The Current State of the Software Development Industry. The technology sector in 2023 was dominated by a few prominent software industry trends that highlighted massive shifts in this space. For', metadata={'query': 'current software development industry trends', 'source': 'https://clickup.com/blog/software-engineering-trends/'}), Document(page_content='Leveraging the Latest Software Development Trends. In 2024, several types of emerging technology are poised to have a massive impact on the software development industry. By staying ahead of the curve', metadata={'query': 'how is software development industry evolving', 'source': 'https://www.stackspot.com/en/blog/software-development-industry'})], 'question': 'What are the latest trends in software development methodologies that companies are utilizing in the current industry landscape?', 'answer': 'The latest trends in software development methodologies that companies are utilizing in the current industry landscape include the adoption of emerging technologies, a focus on innovation, and staying ahead of the curve. Companies are leveraging new methodologies to keep pace with the rapidly evolving software development industry in 2024.'}\n",
      "2024-04-23 12:03:46,768 [MainThread  ] [INFO ]  Generating final answer for [JohnDoe] - \n",
      "\t {'context': [Document(page_content='17 Key Software Development Trends. As we make our way through 2024, the software development industry is rapidly evolving with new technologies, methodologies, and a growing demand for innovative', metadata={'query': 'how is software development industry evolving', 'source': 'https://spdload.com/blog/software-development-trends/'}), Document(page_content='17 Key Software Development Trends. Updated on 1 Apr 2024. 9 min. As we make our way through 2024, the software development industry is rapidly evolving with new technologies, methodologies, and a', metadata={'query': 'current software development industry trends', 'source': 'https://spdload.com/blog/software-development-trends/'}), Document(page_content='The Current State of the Software Development Industry. The technology sector in 2023 was dominated by a few prominent software industry trends that highlighted massive shifts in this space. For', metadata={'query': 'current software development industry trends', 'source': 'https://clickup.com/blog/software-engineering-trends/'}), Document(page_content='Leveraging the Latest Software Development Trends. In 2024, several types of emerging technology are poised to have a massive impact on the software development industry. By staying ahead of the curve', metadata={'query': 'how is software development industry evolving', 'source': 'https://www.stackspot.com/en/blog/software-development-industry'})], 'question': 'What are the latest trends in software development methodologies that companies are utilizing in the current industry landscape?', 'answer': 'The latest trends in software development methodologies that companies are utilizing in the current industry landscape include the adoption of emerging technologies, a focus on innovation, and staying ahead of the curve. Companies are leveraging new methodologies to keep pace with the rapidly evolving software development industry in 2024.'}\n",
      "2024-04-23 12:03:49,217 [MainThread  ] [INFO ]  Genreted final answer answer='The latest trends in software development methodologies that companies are utilizing in the current industry landscape include the adoption of emerging technologies, a focus on innovation, and staying ahead of the curve. Companies are leveraging new methodologies to keep pace with the rapidly evolving software development industry in 2024.' cited_urls=['https://spdload.com/blog/software-development-trends/', 'https://clickup.com/blog/software-engineering-trends/', 'https://www.stackspot.com/en/blog/software-development-industry'] for [JohnDoe] - \n",
      "\t The latest trends in software development methodologies that companies are utilizing in the current industry landscape include the adoption of emerging technologies, a focus on innovation, and staying ahead of the curve. Companies are leveraging new methodologies to keep pace with the rapidly evolving software development industry in 2024.\n",
      "\n",
      "Citations:\n",
      "\n",
      "[1]: https://spdload.com/blog/software-development-trends/\n",
      "[2]: https://clickup.com/blog/software-engineering-trends/\n",
      "[3]: https://www.stackspot.com/en/blog/software-development-industry\n",
      "2024-04-23 12:03:49,218 [MainThread  ] [INFO ]  END - generate answer for [JohnDoe]\n",
      "2024-04-23 12:03:49,232 [MainThread  ] [INFO ]  Generating question for JohnDoe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_question\n",
      "Processing step: answer_question\n",
      "--  [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-tur\n",
      "InterviewState.from_dict: data is an instance of dict\n",
      "Routing messages for [JohnDoe]\n",
      "Continue asking question for [JohnDoe] as this is not the last end of the conversation - ResponseCount: 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:50,033 [MainThread  ] [INFO ]  Generated question for JohnDoe: What are some recent technological advancements in the field of artificial intelligence that have had a significant impact on software development?\n",
      "2024-04-23 12:03:50,053 [MainThread  ] [INFO ]  START - Generate answer for [JohnDoe] - Question: [What are some recent technological advancements in the field of artificial intelligence that have had a significant impact on software development?]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_question\n",
      "Processing step: ask_question\n",
      "--  [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-tur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:51,364 [MainThread  ] [INFO ]  Got 3 search engine queries for [JohnDoe] -\n",
      "\t ['Recent advancements in artificial intelligence impacting software development', 'Technological innovations in AI influencing software development', 'Impact of AI advancements on software development']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [Recent advancements in artificial intelligence impacting software development]\n",
      "Got search engine results: 5 for [Recent advancements in artificial intelligence impacting software development]\n",
      "Searching DuckDuckGo for [Technological innovations in AI influencing software development]\n",
      "Got search engine results: 5 for [Technological innovations in AI influencing software development]\n",
      "Searching DuckDuckGo for [Impact of AI advancements on software development]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:03:54,520 [MainThread  ] [INFO ]  Search result: {'ids': ['24fe1365-558e-4d65-92e1-96a58d5ecb55', '383cc3e9-0ed5-4e47-b2c3-ddbe870c8de0', 'afea5e2d-80d4-4035-add6-9e879ffb9d5c'], 'embeddings': None, 'metadatas': [{'query': 'Latest advancements in natural language processing in artificial intelligence', 'source': 'https://www.technologyreview.com/2024/01/04/1086046/whats-next-for-ai-in-2024/'}, {'query': 'recent AI advancements for software industry', 'source': 'https://www.technologyreview.com/2024/01/04/1086046/whats-next-for-ai-in-2024/'}, {'query': 'latest developments in artificial intelligence relevant to software industry', 'source': 'https://www.technologyreview.com/2024/01/04/1086046/whats-next-for-ai-in-2024/'}], 'documents': ['In 2024, generative AI might actually become useful for the regular, non-tech person, and we are going to see more people tinkering with a million little AI models. State-of-the-art AI models ...', 'In 2024, generative AI might actually become useful for the regular, non-tech person, and we are going to see more people tinkering with a million little AI models. State-of-the-art AI models ...', 'In 2024, generative AI might actually become useful for the regular, non-tech person, and we are going to see more people tinkering with a million little AI models. State-of-the-art AI models ...'], 'uris': None, 'data': None}\n",
      "2024-04-23 12:03:54,521 [MainThread  ] [INFO ]  Vectorstore already has doc: {'source': 'https://www.technologyreview.com/2024/01/04/1086046/whats-next-for-ai-in-2024/'} with ids: ['24fe1365-558e-4d65-92e1-96a58d5ecb55', '383cc3e9-0ed5-4e47-b2c3-ddbe870c8de0', 'afea5e2d-80d4-4035-add6-9e879ffb9d5c']\n",
      "2024-04-23 12:03:54,523 [MainThread  ] [INFO ]  Search result: {'ids': ['343edd81-cebf-4a66-a2de-d9c35f5f7b96', 'cdf0feaf-46e4-4ae4-a144-a8f53f9c3b2b'], 'embeddings': None, 'metadatas': [{'query': 'How is AI being used in software development to improve efficiency and quality?', 'source': 'https://cloud.google.com/blog/products/ai-machine-learning/how-ai-impacts-software-development'}, {'query': 'How is AI being used in software development to improve efficiency and quality?', 'source': 'https://cloud.google.com/blog/products/ai-machine-learning/how-ai-impacts-software-development'}], 'documents': ['AI will help automate tedious and repetitive tasks, such as code reviews, testing, and debugging, which can minimize the time developers spend on these tasks while simultaneously allowing them to', 'allowing them to focus on more meaningful and innovative work. Overall, this can lead to faster development cycles and better quality software.'], 'uris': None, 'data': None}\n",
      "2024-04-23 12:03:54,523 [MainThread  ] [INFO ]  Vectorstore already has doc: {'source': 'https://cloud.google.com/blog/products/ai-machine-learning/how-ai-impacts-software-development'} with ids: ['343edd81-cebf-4a66-a2de-d9c35f5f7b96', 'cdf0feaf-46e4-4ae4-a144-a8f53f9c3b2b']\n",
      "2024-04-23 12:03:54,525 [MainThread  ] [INFO ]  Search result: {'ids': ['343edd81-cebf-4a66-a2de-d9c35f5f7b96', 'cdf0feaf-46e4-4ae4-a144-a8f53f9c3b2b'], 'embeddings': None, 'metadatas': [{'query': 'How is AI being used in software development to improve efficiency and quality?', 'source': 'https://cloud.google.com/blog/products/ai-machine-learning/how-ai-impacts-software-development'}, {'query': 'How is AI being used in software development to improve efficiency and quality?', 'source': 'https://cloud.google.com/blog/products/ai-machine-learning/how-ai-impacts-software-development'}], 'documents': ['AI will help automate tedious and repetitive tasks, such as code reviews, testing, and debugging, which can minimize the time developers spend on these tasks while simultaneously allowing them to', 'allowing them to focus on more meaningful and innovative work. Overall, this can lead to faster development cycles and better quality software.'], 'uris': None, 'data': None}\n",
      "2024-04-23 12:03:54,526 [MainThread  ] [INFO ]  Vectorstore already has doc: {'source': 'https://cloud.google.com/blog/products/ai-machine-learning/how-ai-impacts-software-development'} with ids: ['343edd81-cebf-4a66-a2de-d9c35f5f7b96', 'cdf0feaf-46e4-4ae4-a144-a8f53f9c3b2b']\n",
      "2024-04-23 12:03:54,527 [MainThread  ] [INFO ]  Data stored in vector store. Chunks: 3\n",
      "2024-04-23 12:03:54,527 [MainThread  ] [INFO ]  Got 3 search engine results for [JohnDoe] - stored_chunks=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [Impact of AI advancements on software development]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:04:00,184 [MainThread  ] [INFO ]  Got answer from QA chain for [JohnDoe]: \n",
      "\tQuestion: What are some recent technological advancements in the field of artificial intelligence that have had a significant impact on software development? \n",
      "\tRaw Answer: {'context': [Document(page_content='1. AI-augmented development. AI was all abuzz in 2023 and will keep its popularity in 2024. AI technologies, such as generative AI (GenAI) and machine learning (ML), can augment and speed up the', metadata={'query': 'recent advancements in software development that have significantly impacted industry efficiency and productivity', 'source': 'https://www.simform.com/blog/software-development-trends-2024/'}), Document(page_content='The Current State of the Software Development Industry. The technology sector in 2023 was dominated by a few prominent software industry trends that highlighted massive shifts in this space. For', metadata={'query': 'current software development industry trends', 'source': 'https://clickup.com/blog/software-engineering-trends/'}), Document(page_content='We ranked the top cross-industry trends that matter most for companies and executives. ... To help executives track the latest developments, ... Applied AI and next-generation software development', metadata={'query': 'current software development industry trends', 'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech'}), Document(page_content='Leveraging the Latest Software Development Trends. In 2024, several types of emerging technology are poised to have a massive impact on the software development industry. By staying ahead of the curve', metadata={'query': 'how is software development industry evolving', 'source': 'https://www.stackspot.com/en/blog/software-development-industry'})], 'question': 'What are some recent technological advancements in the field of artificial intelligence that have had a significant impact on software development?', 'answer': 'Recent technological advancements in the field of artificial intelligence that have significantly impacted software development include AI-augmented development using technologies like generative AI and machine learning. Executives are tracking developments in applied AI and next-generation software development as key trends in the industry. Emerging technologies are set to have a massive impact on software development in 2024.'}\n",
      "2024-04-23 12:04:00,184 [MainThread  ] [INFO ]  Generating final answer for [JohnDoe] - \n",
      "\t {'context': [Document(page_content='1. AI-augmented development. AI was all abuzz in 2023 and will keep its popularity in 2024. AI technologies, such as generative AI (GenAI) and machine learning (ML), can augment and speed up the', metadata={'query': 'recent advancements in software development that have significantly impacted industry efficiency and productivity', 'source': 'https://www.simform.com/blog/software-development-trends-2024/'}), Document(page_content='The Current State of the Software Development Industry. The technology sector in 2023 was dominated by a few prominent software industry trends that highlighted massive shifts in this space. For', metadata={'query': 'current software development industry trends', 'source': 'https://clickup.com/blog/software-engineering-trends/'}), Document(page_content='We ranked the top cross-industry trends that matter most for companies and executives. ... To help executives track the latest developments, ... Applied AI and next-generation software development', metadata={'query': 'current software development industry trends', 'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech'}), Document(page_content='Leveraging the Latest Software Development Trends. In 2024, several types of emerging technology are poised to have a massive impact on the software development industry. By staying ahead of the curve', metadata={'query': 'how is software development industry evolving', 'source': 'https://www.stackspot.com/en/blog/software-development-industry'})], 'question': 'What are some recent technological advancements in the field of artificial intelligence that have had a significant impact on software development?', 'answer': 'Recent technological advancements in the field of artificial intelligence that have significantly impacted software development include AI-augmented development using technologies like generative AI and machine learning. Executives are tracking developments in applied AI and next-generation software development as key trends in the industry. Emerging technologies are set to have a massive impact on software development in 2024.'}\n",
      "2024-04-23 12:04:04,591 [MainThread  ] [INFO ]  Genreted final answer answer='Recent technological advancements in the field of artificial intelligence that have significantly impacted software development include AI-augmented development using technologies like generative AI and machine learning. Executives are tracking developments in applied AI and next-generation software development as key trends in the industry. Emerging technologies are set to have a massive impact on software development in 2024.' cited_urls=['https://www.simform.com/blog/software-development-trends-2024/', 'https://clickup.com/blog/software-engineering-trends/', 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech', 'https://www.stackspot.com/en/blog/software-development-industry'] for [JohnDoe] - \n",
      "\t Recent technological advancements in the field of artificial intelligence that have significantly impacted software development include AI-augmented development using technologies like generative AI and machine learning. Executives are tracking developments in applied AI and next-generation software development as key trends in the industry. Emerging technologies are set to have a massive impact on software development in 2024.\n",
      "\n",
      "Citations:\n",
      "\n",
      "[1]: https://www.simform.com/blog/software-development-trends-2024/\n",
      "[2]: https://clickup.com/blog/software-engineering-trends/\n",
      "[3]: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech\n",
      "[4]: https://www.stackspot.com/en/blog/software-development-industry\n",
      "2024-04-23 12:04:04,592 [MainThread  ] [INFO ]  END - generate answer for [JohnDoe]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_question\n",
      "Processing step: answer_question\n",
      "--  [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-tur\n",
      "InterviewState.from_dict: data is an instance of dict\n",
      "Routing messages for [JohnDoe]\n",
      "Reached max number of responses for [JohnDoe] - ResponseCount: 3\n",
      "__end__\n",
      "Processing step: __end__\n",
      "--  [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-tur\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interview_graph = StormInterviewGraph1(interview_config=interview_config)\n",
    "\n",
    "context = \"increase development productivity by using Docker compose and local docker labs\"\n",
    "\n",
    "tm1 = HumanMessage(content=\"What is the best way to increase development productivity by using Docker compose and local docker labs\", name=\"John Smith\")\n",
    "\n",
    "test_state = InterviewState(\n",
    "    context=context,\n",
    "    interview_config=interview_config,\n",
    "    editor=Editor(affiliation=\"Software Company X\", name=\"John Doe\", role=\"Lead Software Engineer\", description=\"Experienced software engineer.\"),\n",
    "    messages=[],\n",
    "    references={}\n",
    ")\n",
    "\n",
    "# Run interview\n",
    "\n",
    "final_step = None\n",
    "async for step in interview_graph.graph.astream(test_state.as_dict()):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(f\"Processing step: {name}\")\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "    if END in step:\n",
    "        final_step = step\n",
    "        \n",
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072ed9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interview_config': {'long_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ff6e710>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11ff7c100>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''),\n",
       "  'fast_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ff272e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11ff6ccd0>, openai_api_key=SecretStr('**********'), openai_proxy=''),\n",
       "  'max_conversations': 3,\n",
       "  'max_reference_length': 10000,\n",
       "  'tags_to_extract': ['p', 'h1', 'h2', 'h3'],\n",
       "  'embeddings': GPT4AllEmbeddings(client=<gpt4all.gpt4all.Embed4All object at 0x10ab8cb20>),\n",
       "  'vectorstore_dir': './data/storm/vectorstore/',\n",
       "  'vectorstore': <langchain_community.vectorstores.chroma.Chroma at 0x10abd7520>,\n",
       "  'interview_graph': None,\n",
       "  'runnable_config': {}},\n",
       " 'editor': {'name': 'John Doe',\n",
       "  'role': 'Lead Software Engineer',\n",
       "  'affiliation': 'Software Company X',\n",
       "  'description': 'Experienced software engineer.'},\n",
       " 'messages': [HumanMessage(content='What are some recent advancements in software development that have significantly impacted the industry in terms of efficiency and productivity?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 163, 'total_tokens': 184}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, name='JohnDoe'),\n",
       "  AIMessage(content='Some recent advancements in software development that have significantly impacted the industry include leveraging emerging technologies, staying ahead of the curve, and focusing on next-generation software development trends. These advancements have aimed to enhance productivity, streamline processes, and accelerate development cycles.\\n\\nCitations:\\n\\n[1]: https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2024/04/17/unlocking-the-future-how-generative-ai-is-revolutionizing-software-engineering/\\n[2]: https://www.stackspot.com/en/blog/software-development-industry\\n[3]: https://clickup.com/blog/software-engineering-trends/\\n[4]: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech', name='JohnDoe'),\n",
       "  HumanMessage(content='What are the latest trends in software development methodologies that companies are utilizing in the current industry landscape?', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 163, 'total_tokens': 182}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, name='JohnDoe'),\n",
       "  AIMessage(content='The latest trends in software development methodologies that companies are utilizing in the current industry landscape include the adoption of emerging technologies, a focus on innovation, and staying ahead of the curve. Companies are leveraging new methodologies to keep pace with the rapidly evolving software development industry in 2024.\\n\\nCitations:\\n\\n[1]: https://spdload.com/blog/software-development-trends/\\n[2]: https://clickup.com/blog/software-engineering-trends/\\n[3]: https://www.stackspot.com/en/blog/software-development-industry', name='JohnDoe'),\n",
       "  HumanMessage(content='What are some recent technological advancements in the field of artificial intelligence that have had a significant impact on software development?', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 163, 'total_tokens': 185}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, name='JohnDoe'),\n",
       "  AIMessage(content='Recent technological advancements in the field of artificial intelligence that have significantly impacted software development include AI-augmented development using technologies like generative AI and machine learning. Executives are tracking developments in applied AI and next-generation software development as key trends in the industry. Emerging technologies are set to have a massive impact on software development in 2024.\\n\\nCitations:\\n\\n[1]: https://www.simform.com/blog/software-development-trends-2024/\\n[2]: https://clickup.com/blog/software-engineering-trends/\\n[3]: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech\\n[4]: https://www.stackspot.com/en/blog/software-development-industry', name='JohnDoe')],\n",
       " 'references': {'https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2024/04/17/unlocking-the-future-how-generative-ai-is-revolutionizing-software-engineering/': 'recent advancements in software development that have significantly impacted industry efficiency and productivity',\n",
       "  'https://www.stackspot.com/en/blog/software-development-industry': 'how is software development industry evolving',\n",
       "  'https://clickup.com/blog/software-engineering-trends/': 'current software development industry trends',\n",
       "  'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech': 'current software development industry trends',\n",
       "  'https://spdload.com/blog/software-development-trends/': 'current software development industry trends',\n",
       "  'https://www.simform.com/blog/software-development-trends-2024/': 'recent advancements in software development that have significantly impacted industry efficiency and productivity'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010d034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = Interviews(topic=example_topic, interview_config=interview_config)\n",
    "\n",
    "# g = StormGraph(interview_config=interview_config, topic=example_topic)\n",
    "# g1 = await g.graph.ainvoke(i.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5210fa50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Text must not be None or empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m qa_chain \u001b[38;5;241m=\u001b[39m get_qa_rag_chain(llm\u001b[38;5;241m=\u001b[39mfast_llm, embeddings\u001b[38;5;241m=\u001b[39membeddings, persistent_location\u001b[38;5;241m=\u001b[39mvectorstore_dir)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mqa_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:2446\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2445\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2446\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2448\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2450\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:3091\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3078\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3079\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3080\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3081\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3089\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3090\u001b[0m         ]\n\u001b[0;32m-> 3091\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3092\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:3091\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3078\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3079\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3080\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3081\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3089\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3090\u001b[0m         ]\n\u001b[0;32m-> 3091\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3092\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/retrievers.py:141\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mstr\u001b[39m, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    140\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/retrievers.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    244\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    248\u001b[0m         result,\n\u001b[1;32m    249\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/retrievers.py:238\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 238\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/vectorstores.py:696\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m    694\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 696\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    698\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    699\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m    700\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[1;32m    701\u001b[0m             )\n\u001b[1;32m    702\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:348\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    333\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:437\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    430\u001b[0m         query_texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[1;32m    431\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    439\u001b[0m         query_embeddings\u001b[38;5;241m=\u001b[39m[query_embedding],\n\u001b[1;32m    440\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_community/embeddings/gpt4all.py:60\u001b[0m, in \u001b[0;36mGPT4AllEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed a query using GPT4All.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m        Embeddings for the text.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_community/embeddings/gpt4all.py:48\u001b[0m, in \u001b[0;36mGPT4AllEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed a list of documents using GPT4All.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m        List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39membed(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, e)) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m embeddings]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_community/embeddings/gpt4all.py:48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed a list of documents using GPT4All.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m        List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, e)) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m embeddings]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/gpt4all/gpt4all.py:56\u001b[0m, in \u001b[0;36mEmbed4All.embed\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Generate an embedding.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        An embedding of your document of text.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt4all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/gpt4all/_pyllmodel.py:281\u001b[0m, in \u001b[0;36mLLModel.generate_embedding\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_embedding\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m text:\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText must not be None or empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m     embedding_size \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_size_t()\n\u001b[1;32m    284\u001b[0m     c_text \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p(text\u001b[38;5;241m.\u001b[39mencode())\n",
      "\u001b[0;31mValueError\u001b[0m: Text must not be None or empty"
     ]
    }
   ],
   "source": [
    "qa_chain = get_qa_rag_chain(llm=fast_llm, embeddings=embeddings, persistent_location=vectorstore_dir)\n",
    "\n",
    "qa_chain.invoke(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb5b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae35f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = outline.invoke(t1)\n",
    "o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79bb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = expand_chain.invoke(t1)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429463f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = gen_perspectives_chain.invoke({\"examples\": r1.topics, \"topic\": example_topic})\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_chain_question_generator(fast_llm)\n",
    "t2 = {\"persona\": \"\"}\n",
    "\n",
    "q1 = c.invoke(t2)\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6716f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_in = {\"messages\": [HumanMessage(content=q1.content, name=\"JohnSmith\")]}\n",
    "a1 = await gen_queries_chain.ainvoke(q_in)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06904c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f625d9f8",
   "metadata": {},
   "source": [
    "# Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cade58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Question node \n",
    "\n",
    "# Test \n",
    "\n",
    "state = InterviewState(\n",
    "    interview_config=interview_config,\n",
    "    editor=Editor(affiliation=\"Example University\", name=\"John Doe\", role=\"Lead Editor\", description=\"Experienced in the field of biology.\"),\n",
    "    messages=[],\n",
    "    references={}\n",
    ")\n",
    "\n",
    "q2 = await node_generate_question.ainvoke(state)\n",
    "q2x = InterviewState.from_dict(q2)\n",
    "q2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a304fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = await node_generate_answer.ainvoke(q2x)\n",
    "q3x = InterviewState.from_dict(q3)\n",
    "q3x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81429d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_route_messages(q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112adea",
   "metadata": {},
   "source": [
    "# Main Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Interviews(topic=example_topic, interview_config=interview_config)\n",
    "i1 = await node_survey_subjects.ainvoke(i)\n",
    "\n",
    "i1x = Interviews.from_dict(i1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bcf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Interviews(topic=example_topic, interview_config=interview_config)\n",
    "\n",
    "g = StormGraph(interview_config=interview_config, topic=example_topic)\n",
    "await g.graph.ainvoke(i.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63098a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interview_graph = StormInterviewGraph1(interview_config=interview_config)\n",
    "\n",
    "# Generate perspectives\n",
    "perspectives = await survey_subjects.ainvoke(example_topic)\n",
    "\n",
    "# Set perspectives\n",
    "interview_graph.interviews.perspectives = perspectives\n",
    "interview_graph.initialize_conversations()\n",
    "logger.info(interview_graph.interviews.conversations.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interview\n",
    "\n",
    "final_step = None\n",
    "# await interview_graph.stream_and_return_results(\n",
    "#     {\"editor\": perspectives.editors[0], \"messages\": []}\n",
    "# )\n",
    "\n",
    "initial_state : InterviewState = InterviewState(interview_config=interview_config, editor=p1.editors[0], messages=[], references={})\n",
    "# {\n",
    "#     \"editor\": p1.editors[0],\n",
    "#     \"messages\": [\n",
    "#         AIMessage(\n",
    "#             content=f\"So you said you were writing an article on {example_topic}?\",\n",
    "#             name=\"SubjectMatterExpert\",\n",
    "#         )\n",
    "#     ],\n",
    "# }\n",
    "async for step in interview_graph.graph.astream(initial_state.as_dict()):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(f\"Processing step: {name}\")\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "    if END in step:\n",
    "        final_step = step\n",
    "        \n",
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state = next(iter(step.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "state2 = InterviewState.from_dict(final_state)\n",
    "state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b02cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state2.trim_messages(max_characters=1000)\n",
    "# final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244c235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bad132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca82998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e9c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ef45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88d122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b278d8c-9e34-42ab-9649-bc7b3570bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Generate Initial Outline\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a Wikipedia writer. Write an outline for a Wikipedia page about a user-provided topic. Be comprehensive and specific.\",\n",
    "        ),\n",
    "        (\"user\", \"{topic}\\n{format_instructions}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    description: str = Field(..., title=\"Content of the subsection\")\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.description}\".strip()\n",
    "\n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    description: str = Field(..., title=\"Content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"### {subsection.subsection_title}\\n\\n{subsection.description}\"\n",
    "            for subsection in self.subsections or []\n",
    "        )\n",
    "        return f\"## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the Wikipedia page\")\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and descriptions for each section of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
    "\n",
    "\n",
    "outline_parser = PydanticOutputParser(pydantic_object=Outline)\n",
    "\n",
    "generate_outline_direct = direct_gen_outline_prompt.partial(format_instructions=outline_parser.get_format_instructions()) | fast_llm | outline_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee8329-896b-4085-a1fa-fec0a15937ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_topic = \"Impact of million-plus token context window language models on RAG\"\n",
    "\n",
    "initial_outline = generate_outline_direct.invoke({\"topic\": example_topic})\n",
    "\n",
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c37266-d5d5-4fbb-831f-8f809e966236",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expand Topics\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f63ad0-7e07-48ac-85a9-80a53b528c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"I'm writing a Wikipedia page for a topic mentioned below. Please identify and recommend some Wikipedia pages on closely related subjects. I'm looking for examples that provide insights into interesting aspects commonly associated with this topic, or examples that help me understand the typical content and structure included in Wikipedia pages for similar topics.\n",
    "\n",
    "Please list the as many subjects and urls as you can.\n",
    "\n",
    "Topic of interest: {topic}\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Comprehensive list of related subjects as background research.\",\n",
    "    )\n",
    "\n",
    "\n",
    "related_topics_parser = PydanticOutputParser(pydantic_object=RelatedSubjects)\n",
    "\n",
    "expand_chain = gen_related_topics_prompt.partial(format_instructions=related_topics_parser.get_format_instructions()) | fast_llm | related_topics_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f801936-f6f7-44a0-bc79-4f0132fba79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_subjects = await expand_chain.ainvoke({\"topic\": example_topic})\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc42a4-45f1-470c-a3f6-20a5661d5b43",
   "metadata": {},
   "source": [
    "## Generate Perspectives\n",
    "\n",
    "From these related subjects, we can select representative Wikipedia editors as \"subject matter experts\" with distinct backgrounds and affiliations. These will help distribute the search process to encourage a more well-rounded final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ea824-c561-4949-bbd4-127281f3eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Editor(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description=\"Primary affiliation of the editor.\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the editor.\",\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the editor in the context of the topic.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Description of the editor's focus, concerns, and motives.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    editors: List[Editor] = Field(\n",
    "        description=\"Comprehensive list of editors with their roles and affiliations.\",\n",
    "        # Add a pydantic validation/restriction to be at most M editors\n",
    "    )\n",
    "\n",
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You need to select a diverse (and distinct) group of Wikipedia editors who will work together to create a comprehensive article on the topic. Each of them represents a different perspective, role, or affiliation related to this topic.\\\n",
    "    You can use other Wikipedia pages of related topics for inspiration. For each editor, add a description of what they will focus on.\n",
    "\n",
    "    Wiki page outlines of related topics for inspiration:\n",
    "    {examples}\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"Topic of interest: {topic}\\n\\n{format_instructions}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "perspectives_parser = PydanticOutputParser(pydantic_object=Perspectives)\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt.partial(format_instructions=perspectives_parser.get_format_instructions()) | fast_llm | perspectives_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a87f7-a867-42f7-ac98-da7ce1110daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda, chain as as_runnable\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
    "\n",
    "\n",
    "def format_doc(doc, max_length=1000)-> str:\n",
    "    related = \"- \".join(doc.metadata[\"categories\"])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\n\\nRelated\\n{related}\"[\n",
    "        :max_length\n",
    "    ]\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def survey_subjects(topic: str)-> Perspectives:\n",
    "    print(f\"Survey Subjects for Topic: {topic}\")\n",
    "    related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(\n",
    "        related_subjects.topics, return_exceptions=True\n",
    "    )\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "    print(f\"Retrieved {len(all_docs)} docs for Topic: {topic}\")\n",
    "    \n",
    "    formatted = format_docs(all_docs)\n",
    "    return await gen_perspectives_chain.ainvoke({\"examples\": formatted, \"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2b5eb-46cb-410f-8b15-6fc8ead58382",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = await survey_subjects.ainvoke(example_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90dd94-b215-4a5d-83b2-498e969ff7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perspectives.dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abdf40-80dc-434c-8116-d6b9cbde5572",
   "metadata": {},
   "source": [
    "## Expert Dialog\n",
    "\n",
    "Each wikipedia writer is primed to role-play using the perspectives presented above. It will ask a series of questions of a second \"domain expert\" with access to a search engine. This generate content to generate a refined outline as well as an updated index of reference documents.\n",
    "\n",
    "### Interview State\n",
    "\n",
    "The conversation is cyclic, so we will construct it within its own graph. The State will contain messages, the reference docs, and the editor (with its own \"persona\") to make it easy to parallelize these conversations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fa250-8b81-465b-ba06-fe7b33e4d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "\n",
    "def add_messages(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    return left + right\n",
    "\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    # Can only set at the outset\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0639d2-e8a6-43d4-8e9a-eb5f4051578c",
   "metadata": {},
   "source": [
    "# Dialog Roles\n",
    "\n",
    "The graph will have two participants: the wikipedia editor (generate_question), who asks questions based on its assigned role, and a domain expert (`gen_answer_chain), who uses a search engine to answer the questions as accurately as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644c46c-4d23-49e1-9093-39b4f6c8c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an experienced Wikipedia writer and want to edit a specific page. \\\n",
    "Besides your identity as a Wikipedia writer, you have a specific focus when researching the topic. \\\n",
    "Now, you are chatting with an expert to get information. Ask good questions to get more useful information.\n",
    "\n",
    "When you have no more questions to ask, say \"Thank you so much for your help!\" to end the conversation.\\\n",
    "Please only ask one question at a time and don't ask what you have asked before.\\\n",
    "Your questions should be related to the topic you want to write.\n",
    "Be comprehensive and curious, gaining as much unique insight from the expert as possible.\\\n",
    "\n",
    "Stay true to your specific perspective:\n",
    "\n",
    "{persona}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def tag_with_name(ai_message: AIMessage, name: str) -> AIMessage:\n",
    "    ai_message.name = name\n",
    "    return ai_message\n",
    "\n",
    "\n",
    "def swap_roles(state: InterviewState, name: str) -> InterviewState:\n",
    "\n",
    "    # Normalize name\n",
    "    name = cleanup_name(name)\n",
    "\n",
    "    print(f'Swapping roles for {name}')\n",
    "\n",
    "    converted = []\n",
    "    for message in state[\"messages\"]:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
    "        converted.append(message)\n",
    "    \n",
    "    print(f'Converted messages for {name} while swapping roles: {len(converted)} messages')\n",
    "\n",
    "    return {\"messages\": converted}\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def generate_question(state: InterviewState) -> InterviewState:\n",
    "    editor = state[\"editor\"]\n",
    "\n",
    "    name = cleanup_name(editor.name)\n",
    "\n",
    "    print(f'Generating question for {name}')\n",
    "\n",
    "    gn_chain = (\n",
    "        RunnableLambda(swap_roles).bind(name=name)\n",
    "        | gen_qn_prompt.partial(persona=editor.persona)\n",
    "        | fast_llm\n",
    "        | RunnableLambda(tag_with_name).bind(name=name)\n",
    "    )\n",
    "    result:AIMessage = await gn_chain.ainvoke(state)\n",
    "\n",
    "    print(f'Generated question for {name}')\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac2384-a123-467f-bbc6-828be9dc04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(f\"So you said you were writing an article on {example_topic}?\")\n",
    "]\n",
    "question = await generate_question.ainvoke(\n",
    "    {\n",
    "        \"editor\": perspectives.editors[0],\n",
    "        \"messages\": messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "question[\"messages\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e50f7-4e2c-4307-853d-2fc8f0b3dd82",
   "metadata": {},
   "source": [
    "### Answer questions\n",
    "\n",
    "The `gen_answer_chain` first generates queries (query expansion) to answer the editor's question, then responds with citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa969e-920f-487e-b124-6495777a1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        description=\"Comprehensive list of search engine queries to answer the user's questions.\",\n",
    "    )\n",
    "\n",
    "\n",
    "gen_queries_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful research assistant. Query the search engine to answer the user's questions.\\n{format_instructions}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "queries_parser = PydanticOutputParser(pydantic_object=Queries)\n",
    "\n",
    "gen_queries_chain = gen_queries_prompt.partial(format_instructions=queries_parser.get_format_instructions()) | fast_llm | queries_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25baa82-da8e-41ec-b4e0-8a24c7cf737d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "queries = await gen_queries_chain.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22273c9a-a505-40c3-bd6b-70f74393a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AnswerWithCitations(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"Comprehensive answer to the user's question with citations.\",\n",
    "    )\n",
    "    cited_urls: List[str] = Field(\n",
    "        description=\"List of urls cited in the answer.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.answer}\\n\\nCitations:\\n\\n\" + \"\\n\".join(\n",
    "            f\"[{i+1}]: {url}\" for i, url in enumerate(self.cited_urls)\n",
    "        )\n",
    "\n",
    "\n",
    "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert who can use information effectively. You are chatting with a Wikipedia writer who wants\\\n",
    " to write a Wikipedia page on the topic you know. You have gathered the related information and will now use the information to form a response.\n",
    "\n",
    "Make your response as informative as possible and make sure every sentence is supported by the gathered information.\n",
    "Each response must be backed up by a citation from a reliable source, formatted as a footnote, reproducing the URLS after your response.\n",
    "{format_instructions}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ac_parser = PydanticOutputParser(pydantic_object=AnswerWithCitations)\n",
    "\n",
    "gen_answer_chain = gen_answer_prompt.partial(format_instructions=ac_parser.get_format_instructions()) | fast_llm | ac_parser \n",
    "\n",
    "# .with_structured_output(\n",
    "#     AnswerWithCitations, include_raw=True\n",
    "# ).with_config(run_name=\"GenerateAnswer\")\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39c4f4-f2ca-4504-84f9-ff1a86b01d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# DDG \n",
    "search_engine = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "@tool\n",
    "async def search_engine(query: str):\n",
    "    \"\"\"Search engine to the internet.\"\"\"\n",
    "\n",
    "    print(f\"Searching DuckDuckGo for [{query}]\")\n",
    "\n",
    "    results = DuckDuckGoSearchAPIWrapper()._ddgs_text(query)\n",
    "\n",
    "    print(f\"Got search engine results: {len(results)} for [{query}]\")\n",
    "    \n",
    "    return [{\"content\": r[\"body\"], \"url\": r[\"href\"]} for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74edcc-a272-4ec1-92fc-756bf0690e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "import json, re\n",
    "\n",
    "\n",
    "async def gen_answer(\n",
    "    state: InterviewState,\n",
    "    config: Optional[RunnableConfig] = None,\n",
    "    name: str = \"SubjectMatterExpert\",\n",
    "    max_str_len: int = 15000,\n",
    "):\n",
    "    name = cleanup_name(name)\n",
    "\n",
    "    print(f'Generating answers for [{name}]')\n",
    "\n",
    "\n",
    "    swapped_state = swap_roles(state, name)  # Convert all other AI messages\n",
    "    \n",
    "    queries:Queries = await gen_queries_chain.ainvoke(swapped_state)\n",
    "\n",
    "    print(f\"Got {len(queries.queries)} search engine queries for [{name}]\")\n",
    "\n",
    "    query_results = await search_engine.abatch(\n",
    "        queries.queries, config, return_exceptions=True\n",
    "    )\n",
    "    successful_results = [\n",
    "        res for res in query_results if not isinstance(res, Exception)\n",
    "    ]\n",
    "\n",
    "    print(f\"Got {len(successful_results)} search engine results for [{name}]\")\n",
    "\n",
    "    all_query_results = {\n",
    "        res[\"url\"]: res[\"content\"] for results in successful_results for res in results\n",
    "    }\n",
    "\n",
    "    # We could be more precise about handling max token length if we wanted to here\n",
    "    dumped = json.dumps(all_query_results)[:max_str_len]\n",
    "    \n",
    "    ai_message: AIMessage = str(queries)\n",
    "    # print(f\"Got {ai_message} for [{name}]\")\n",
    "    \n",
    "    # tool_call = queries[\"raw\"].additional_kwargs[\"tool_calls\"][0]\n",
    "    # tool_id = tool_call[\"id\"]\n",
    "\n",
    "    # tool_message = ToolMessage(tool_call_id=tool_id, content=dumped)\n",
    "    tool_message = HumanMessage(content=dumped)\n",
    "\n",
    "    swapped_state[\"messages\"].extend([ai_message, tool_message])\n",
    "    \n",
    "    # Only update the shared state with the final answer to avoid\n",
    "    # polluting the dialogue history with intermediate messages\n",
    "    try:\n",
    "        generated: AnswerWithCitations = await gen_answer_chain.ainvoke(swapped_state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer for [{name}] - {e}\")\n",
    "        generated = AnswerWithCitations(answer=\"\", cited_urls=[])\n",
    "    \n",
    "    cited_urls = set(generated.cited_urls)\n",
    "    \n",
    "    # Save the retrieved information to a the shared state for future reference\n",
    "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
    "    \n",
    "    formatted_message = AIMessage(name=name, content=generated.as_str)\n",
    "\n",
    "    print(f'Finished generating answer for [{name}]')\n",
    "    return {\"messages\": [formatted_message], \"references\": cited_references}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934aafd6-7f0d-4a1b-8a52-45b89d8b3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_answer = await gen_answer(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "example_answer[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998671bf-958d-44c0-8421-523a71bea01a",
   "metadata": {},
   "source": [
    "# Construct the Interview Graph\n",
    "\n",
    "Now that we've defined the editor and domain expert, we can compose them in a graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800f958-00e0-4913-a246-c34dc3f0a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_turns = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "builder = StateGraph(InterviewState)\n",
    "\n",
    "builder.add_node(\"ask_question\", generate_question)\n",
    "builder.add_node(\"answer_question\", gen_answer)\n",
    "builder.add_conditional_edges(\"answer_question\", route_messages)\n",
    "builder.add_edge(\"ask_question\", \"answer_question\")\n",
    "\n",
    "builder.set_entry_point(\"ask_question\")\n",
    "interview_graph = builder.compile().with_config(run_name=\"Conduct Interviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c405fc-5b1c-44f5-b860-a10fe0d6616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# comment out if you have not installed pygraphviz\n",
    "# Image(interview_graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d47607-6c0b-493a-aebc-48356d0e0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_step = None\n",
    "\n",
    "initial_state = {\n",
    "    \"editor\": perspectives.editors[0],\n",
    "    \"messages\": [\n",
    "        AIMessage(\n",
    "            content=f\"So you said you were writing an article on {example_topic}?\",\n",
    "            name=\"SubjectMatterExpert\",\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "async for step in interview_graph.astream(initial_state):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(f\"Processing step: {name}\")\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "    if END in step:\n",
    "        final_step = step\n",
    "        \n",
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a97ec-09a1-4873-b559-275526971a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e14dcb",
   "metadata": {},
   "source": [
    "## Refine Outline\n",
    "\n",
    "At this point in STORM, we've conducted a large amount of research from different perspectives. It's time to refine the original outline based on these investigations. Below, create a chain using the LLM with a long context window to update the original outline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284eb72-3856-406d-8582-5a1c92fd292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a Wikipedia writer. You have gathered information from experts and search engines. Now, you are refining the outline of the Wikipedia page. \\\n",
    "You need to make sure that the outline is comprehensive and specific. \\\n",
    "Topic you are writing about: {topic} \n",
    "\n",
    "Old outline:\n",
    "\n",
    "{old_outline}\n",
    "\"\"\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Refine the outline based on your conversations with subject-matter experts:\\n\\nConversations:\\n\\n{conversations}\\n\\n{format_instructions}\\n\\nWrite the refined Wikipedia outline:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Using turbo preview since the context can get quite long\n",
    "refine_outline_chain = refine_outline_prompt.partial(format_instructions=outline_parser.get_format_instructions()) | long_context_llm | outline_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e58c5-086f-49ba-b921-791669d04b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_outline = refine_outline_chain.invoke(\n",
    "    {\n",
    "        \"topic\": example_topic,\n",
    "        \"old_outline\": initial_outline.as_str,\n",
    "        \"conversations\": \"\\n\\n\".join(\n",
    "            f\"### {m.name}\\n\\n{m.content}\" for m in final_state[\"messages\"]\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c397dc5-e614-4a7f-9f78-67dffc9b8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refined_outline.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "reference_docs = [\n",
    "    Document(page_content=v, metadata={\"source\": k})\n",
    "    for k, v in final_state[\"references\"].items()\n",
    "]\n",
    "\n",
    "print(f\"Number of references: {len(reference_docs)}\")\n",
    "\n",
    "# This really doesn't need to be a vectorstore for this size of data.\n",
    "# It could just be a numpy matrix. Or you could store documents\n",
    "# across requests if you want.\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    reference_docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05496dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"What's a long context LLM anyway?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708d31a",
   "metadata": {},
   "source": [
    "#### Generate Sections\n",
    "\n",
    "Now you can generate the sections using the indexed docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    content: str = Field(\n",
    "        ...,\n",
    "        title=\"Full content of the subsection. Include [#] citations to the cited sources where relevant.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.content}\".strip()\n",
    "\n",
    "\n",
    "class WikiSection(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    content: str = Field(..., title=\"Full content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "    citations: List[str] = Field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            subsection.as_str for subsection in self.subsections or []\n",
    "        )\n",
    "        citations = \"\\n\".join([f\" [{i}] {cit}\" for i, cit in enumerate(self.citations)])\n",
    "        return (\n",
    "            f\"## {self.section_title}\\n\\n{self.content}\\n\\n{subsections}\".strip()\n",
    "            + f\"\\n\\n{citations}\".strip()\n",
    "        )\n",
    "\n",
    "\n",
    "section_writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia writer. Complete your assigned WikiSection from the following outline:\\n\\n\"\n",
    "            \"{outline}\\n\\nCite your sources, using the following references:\\n\\n<Documents>\\n{docs}\\n<Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"Write the full WikiSection for the {section} section.\\n{format_instructions}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def retrieve(inputs: dict):\n",
    "    docs = await retriever.ainvoke(inputs[\"topic\"] + \": \" + inputs[\"section\"])\n",
    "    formatted = \"\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "    return {\"docs\": formatted, **inputs}\n",
    "\n",
    "wiki_parser = PydanticOutputParser(pydantic_object=WikiSection)\n",
    "\n",
    "section_writer = (\n",
    "    retrieve\n",
    "    | section_writer_prompt.partial(format_instructions=wiki_parser.get_format_instructions())\n",
    "    | long_context_llm\n",
    "    | wiki_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03723e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = await section_writer.ainvoke(\n",
    "    {\n",
    "        \"outline\": refined_outline.as_str,\n",
    "        \"section\": refined_outline.sections[1].section_title,\n",
    "        \"topic\": example_topic,\n",
    "    }\n",
    ")\n",
    "print(section.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd728d",
   "metadata": {},
   "source": [
    "#### Generate final article\n",
    "\n",
    "Now we can rewrite the draft to appropriately group all the citations and maintain a consistent voice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05089f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia author. Write the complete wiki article on {topic} using the following section drafts:\\n\\n\"\n",
    "            \"{draft}\\n\\nStrictly follow Wikipedia format guidelines.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            'Write the complete Wiki article using markdown format. Organize citations using footnotes like \"[1]\",\"\" avoiding duplicates in the footer. Include URLs in the footer.',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | long_context_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in writer.stream({\"topic\": example_topic, \"draft\": section.as_str}):\n",
    "    print(tok, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ab734",
   "metadata": {},
   "source": [
    "## Final Flow\n",
    "\n",
    "Now it's time to string everything together. We will have 6 main stages in sequence:\n",
    ".\n",
    "\n",
    "1. Generate the initial outline + perspectives\n",
    "2. Batch converse with each perspective to expand the content for the article\n",
    "3. Refine the outline based on the conversations\n",
    "4. Index the reference docs from the conversations\n",
    "5. Write the individual sections of the article\n",
    "6. Write the final wiki\n",
    "\n",
    "The state tracks the outputs of each stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    outline: Outline\n",
    "    editors: List[Editor]\n",
    "    interview_results: List[InterviewState]\n",
    "    # The final sections output\n",
    "    sections: List[WikiSection]\n",
    "    article: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def initialize_research(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    coros = (\n",
    "        generate_outline_direct.ainvoke({\"topic\": topic}),\n",
    "        survey_subjects.ainvoke(topic),\n",
    "    )\n",
    "    results = await asyncio.gather(*coros)\n",
    "    return {\n",
    "        **state,\n",
    "        \"outline\": results[0],\n",
    "        \"editors\": results[1].editors,\n",
    "    }\n",
    "\n",
    "\n",
    "async def conduct_interviews(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    initial_states = [\n",
    "        {\n",
    "            \"editor\": editor,\n",
    "            \"messages\": [\n",
    "                AIMessage(\n",
    "                    content=f\"So you said you were writing an article on {topic}?\",\n",
    "                    name=\"SubjectMatterExpert\",\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "        for editor in state[\"editors\"]\n",
    "    ]\n",
    "    # We call in to the sub-graph here to parallelize the interviews\n",
    "    interview_results = await interview_graph.abatch(initial_states)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"interview_results\": interview_results,\n",
    "    }\n",
    "\n",
    "\n",
    "def format_conversation(interview_state):\n",
    "    messages = interview_state[\"messages\"]\n",
    "    convo = \"\\n\".join(f\"{m.name}: {m.content}\" for m in messages)\n",
    "    return f'Conversation with {interview_state[\"editor\"].name}\\n\\n' + convo\n",
    "\n",
    "\n",
    "async def refine_outline(state: ResearchState):\n",
    "    convos = \"\\n\\n\".join(\n",
    "        [\n",
    "            format_conversation(interview_state)\n",
    "            for interview_state in state[\"interview_results\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    updated_outline = await refine_outline_chain.ainvoke(\n",
    "        {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"old_outline\": state[\"outline\"].as_str,\n",
    "            \"conversations\": convos,\n",
    "        }\n",
    "    )\n",
    "    return {**state, \"outline\": updated_outline}\n",
    "\n",
    "\n",
    "async def index_references(state: ResearchState):\n",
    "    all_docs = []\n",
    "    for interview_state in state[\"interview_results\"]:\n",
    "        reference_docs = [\n",
    "            Document(page_content=v, metadata={\"source\": k})\n",
    "            for k, v in interview_state[\"references\"].items()\n",
    "        ]\n",
    "        all_docs.extend(reference_docs)\n",
    "    await vectorstore.aadd_documents(all_docs)\n",
    "    return state\n",
    "\n",
    "\n",
    "async def write_sections(state: ResearchState):\n",
    "    outline = state[\"outline\"]\n",
    "    sections = await section_writer.abatch(\n",
    "        [\n",
    "            {\n",
    "                \"outline\": refined_outline.as_str,\n",
    "                \"section\": section.section_title,\n",
    "                \"topic\": state[\"topic\"],\n",
    "            }\n",
    "            for section in outline.sections\n",
    "        ]\n",
    "    )\n",
    "    return {\n",
    "        **state,\n",
    "        \"sections\": sections,\n",
    "    }\n",
    "\n",
    "\n",
    "async def write_article(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state[\"sections\"]\n",
    "    draft = \"\\n\\n\".join([section.as_str for section in sections])\n",
    "    article = await writer.ainvoke({\"topic\": topic, \"draft\": draft})\n",
    "    return {\n",
    "        **state,\n",
    "        \"article\": article,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87881e3",
   "metadata": {},
   "source": [
    "#### Create the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_of_storm = StateGraph(ResearchState)\n",
    "\n",
    "nodes = [\n",
    "    (\"init_research\", initialize_research),\n",
    "    (\"conduct_interviews\", conduct_interviews),\n",
    "    (\"refine_outline\", refine_outline),\n",
    "    (\"index_references\", index_references),\n",
    "    (\"write_sections\", write_sections),\n",
    "    (\"write_article\", write_article),\n",
    "]\n",
    "for i in range(len(nodes)):\n",
    "    name, node = nodes[i]\n",
    "    builder_of_storm.add_node(name, node)\n",
    "    if i > 0:\n",
    "        builder_of_storm.add_edge(nodes[i - 1][0], name)\n",
    "\n",
    "builder_of_storm.set_entry_point(nodes[0][0])\n",
    "builder_of_storm.set_finish_point(nodes[-1][0])\n",
    "storm = builder_of_storm.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a815f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for step in storm.astream(\n",
    "    {\n",
    "        \"topic\": \"Building better slack bots using LLMs\",\n",
    "    }\n",
    "):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name])[:300])\n",
    "    if END in step:\n",
    "        results = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = results[END][\"article\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b094067",
   "metadata": {},
   "source": [
    "## Render the Wiki\n",
    "\n",
    "Now we can render the final wiki page!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7750c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# We will down-header the sections to create less confusion in this notebook\n",
    "Markdown(article.replace(\"\\n#\", \"\\n##\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e24611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
