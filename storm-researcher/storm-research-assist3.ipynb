{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b912966-4dce-4685-a5b2-a39c5229a0f1",
   "metadata": {},
   "source": [
    "# Storm Research Assistant\n",
    "\n",
    "Reference\n",
    "https://github.com/langchain-ai/langgraph/blob/main/examples/storm/storm.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54832538-aa97-4e40-9713-eaae1e62852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Prereqs\n",
    "\n",
    "# %pip install -U langchain_community langchain_openai langgraph wikipedia  scikit-learn  langchain_fireworks\n",
    "# # We use one or the other search engine below\n",
    "# %pip install -U tavily-python\n",
    "# %pip install -U duckduckgo-search\n",
    "# # ! apt-get install graphviz graphviz-dev\n",
    "# # %pip install pygraphviz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32108c2-977f-450d-82cb-90aa21f09171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from storm import *\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "fast_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "# long_context_llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "long_context_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# haiku model\n",
    "# haiku_model_name = \"claude-3-haiku-20240307\"\n",
    "# fast_llm = ChatAnthropic(model_name=haiku_model_name)\n",
    "# long_context_llm = ChatAnthropic(model_name=haiku_model_name)\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore_dir = \"./data/storm/vectorstore/\"\n",
    "vectorstore = Chroma(persist_directory=vectorstore_dir, embedding_function=embeddings)\n",
    "\n",
    "interview_config = InterviewConfig(long_llm=long_context_llm, \n",
    "                                   fast_llm=fast_llm, \n",
    "                                   max_conversations=3, \n",
    "                                   max_reference_length=10000,\n",
    "                                   tags_to_extract=[ \"p\", \"h1\", \"h2\", \"h3\"],\n",
    "                                   embeddings=embeddings,\n",
    "                                   vectorstore=vectorstore,\n",
    "                                   vectorstore_dir=vectorstore_dir,\n",
    "                                   runnable_config=RunnableConfig()\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8209e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs topic as input - {\"topic\": \"\"}\n",
    "outline = get_chain_outline(interview_config.fast_llm)\n",
    "\n",
    "# Needs topic as input - {\"topic\": \"\"}\n",
    "expand_chain = get_chain_expand_related_topics(fast_llm)\n",
    "\n",
    "\n",
    "gen_perspectives_chain = get_chain_perspective_generator(fast_llm)\n",
    "\n",
    "# Need messages as input - {\"messages\": []}\n",
    "gen_queries_chain = get_chain_queries(fast_llm)\n",
    "gen_answer_chain = get_chain_answer(fast_llm)\n",
    "\n",
    "example_topic = \"Increase development productivity by using Docker compose and local docker labs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010d034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Survey Subjects for Topic: [Increase development productivity by using Docker compose and local docker labs] --\n",
      "\n",
      "Related Subjects: ['Docker (software)', 'Containerization', 'DevOps', 'Continuous Integration', 'Software Development', 'Virtualization', 'Microservices']\n",
      "Retrieved 7 wiki batches for Topic: Increase development productivity by using Docker compose and local docker labs:\n",
      "\n",
      "\tDocker (software) - https://en.wikipedia.org/wiki/Docker_(software)\n",
      "\tDocker, Inc. - https://en.wikipedia.org/wiki/Docker,_Inc.\n",
      "\tContainerization - https://en.wikipedia.org/wiki/Containerization\n",
      "\tContainerization (computing) - https://en.wikipedia.org/wiki/Containerization_(computing)\n",
      "\tDevOps - https://en.wikipedia.org/wiki/DevOps\n",
      "\tAzure DevOps Server - https://en.wikipedia.org/wiki/Azure_DevOps_Server\n",
      "\tContinuous integration - https://en.wikipedia.org/wiki/Continuous_integration\n",
      "\tComparison of continuous integration software - https://en.wikipedia.org/wiki/Comparison_of_continuous_integration_software\n",
      "\tSoftware development - https://en.wikipedia.org/wiki/Software_development\n",
      "\tScrum (software development) - https://en.wikipedia.org/wiki/Scrum_(software_development)\n",
      "\tVirtualization - https://en.wikipedia.org/wiki/Virtualization\n",
      "\tX86 virtualization - https://en.wikipedia.org/wiki/X86_virtualization\n",
      "\tMicroservices - https://en.wikipedia.org/wiki/Microservices\n",
      "\tService-oriented architecture - https://en.wikipedia.org/wiki/Service-oriented_architecture\n",
      "Retrieved 14 docs for Topic: Increase development productivity by using Docker compose and local docker labs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:09,864 [MainThread  ] [INFO ]  Generating question for Alice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 perspectives for Topic: [Increase development productivity by using Docker compose and local docker labs]\n",
      "\n",
      ">> Generated perspective for: Alice \n",
      "Affiliation: - Software Development Company\n",
      "Persona: - Name: Alice\n",
      "Role: Software Engineer\n",
      "Affiliation: Software Development Company\n",
      "Description: Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.\n",
      "\n",
      "Topic: - Increase development productivity by using Docker compose and local docker labs\n",
      "\n",
      ">> Generated perspective for: Bob \n",
      "Affiliation: - Technology Consulting Firm\n",
      "Persona: - Name: Bob\n",
      "Role: DevOps Specialist\n",
      "Affiliation: Technology Consulting Firm\n",
      "Description: Bob specializes in DevOps practices and will provide guidance on integrating Docker compose and local Docker labs into the DevOps pipeline. He will focus on automation, scalability, and the overall impact on the software development lifecycle.\n",
      "\n",
      "Topic: - Increase development productivity by using Docker compose and local docker labs\n",
      "\n",
      ">> Generated perspective for: Charlie \n",
      "Affiliation: - Cloud Computing Provider\n",
      "Persona: - Name: Charlie\n",
      "Role: Cloud Architect\n",
      "Affiliation: Cloud Computing Provider\n",
      "Description: Charlie will offer insights on how Docker compose and local Docker labs can be effectively utilized in cloud environments. He will focus on scalability, security considerations, and the orchestration of containers for large-scale projects.\n",
      "\n",
      "Topic: - Increase development productivity by using Docker compose and local docker labs\n",
      "\n",
      ">> Generated perspective for: Diana \n",
      "Affiliation: - Open Source Community\n",
      "Persona: - Name: Diana\n",
      "Role: Open Source Contributor\n",
      "Affiliation: Open Source Community\n",
      "Description: Diana is an active contributor to open source projects related to Docker and containerization. She will focus on the community-driven aspects of using Docker compose and local Docker labs, including collaboration, sharing knowledge, and contributing to the ecosystem.\n",
      "\n",
      "Topic: - Increase development productivity by using Docker compose and local docker labs\n",
      "\n",
      ">> Generated perspective for: Eve \n",
      "Affiliation: - Academic Institution\n",
      "Persona: - Name: Eve\n",
      "Role: Researcher\n",
      "Affiliation: Academic Institution\n",
      "Description: Eve conducts research on software development methodologies and tools. She will provide insights into the theoretical foundations behind using Docker compose and local Docker labs to enhance productivity, including academic perspectives, case studies, and future trends.\n",
      "\n",
      "Topic: - Increase development productivity by using Docker compose and local docker labs\n",
      "\n",
      "==================\n",
      "Saving data to interviews.json\n",
      "\n",
      "{'topic': 'Increase development productivity by using Docker compose and local docker labs', 'related_subjects': {'topics': ['Docker (software)', 'Containerization', 'DevOps', 'Continuous Integration', 'Software Development', 'Virtualization', 'Microservices']}, 'related_subjects_formatted': \"### Docker (software)\\n\\nSummary: Docker is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers. \\nThe service has both free and premium tiers. The software that hosts the containers is called Docker Engine. It was first released in 2013 and is developed by Docker, Inc.\\nDocker is a tool that is used to automate the deployment of applications in lightweight containers so that applications can work efficiently in different \\n\\n### Docker, Inc.\\n\\nSummary: Docker, Inc. is an American technology company that develops productivity tools built around Docker, which automates the deployment of code inside software containers. Major commercial products of the company are Docker Hub, a central repository of containers, Docker Desktop, a GUI application for Windows and Mac to manage containers. The historic offering was Docker Enterprise PaaS business, acquired by Mirantis. The company is also an active contributor to various CN\\n\\n### Containerization\\n\\nSummary: Containerization is a system of intermodal freight transport using intermodal containers (also called shipping containers, or ISO containers). Containerization, also referred as container stuffing or container loading, is the process of unitization of cargoes in exports. Containerization is the predominant form of unitization of export cargoes, as opposed to other systems such as the barge system or palletization. The containers have standardized dimensions. They c\\n\\n### Containerization (computing)\\n\\nSummary: In software engineering, containerization is operating system-level virtualization or application-level virtualization over multiple network resources so that software applications can run in isolated user spaces called containers in any cloud or non-cloud environment, regardless of type or vendor.\\n\\n\\n== Usage ==\\nThe containers are basically a fully functional and portable cloud or non-cloud computing environment surrounding the application and keeping i\\n\\n### DevOps\\n\\nSummary: DevOps is a methodology in the software development and IT industry. Used as a set of practices and tools, DevOps integrates and automates the work of software development (Dev) and IT operations (Ops) as a means for improving and shortening the systems development life cycle. DevOps is complementary to agile software development; several DevOps aspects came from the agile way of working.\\n\\n\\n== Definition ==\\nOther than it being a cross-functional combination (and a portmantea\\n\\n### Azure DevOps Server\\n\\nSummary: Azure DevOps Server, formerly known as Team Foundation Server (TFS) and Visual Studio Team System (VSTS), is a Microsoft product that provides version control (either with Team Foundation Version Control (TFVC) or Git), reporting, requirements management, project management (for both agile software development and waterfall teams), automated builds, testing and release management capabilities. It covers the entire application lifecycle and enables DevOps capabil\\n\\n### Continuous integration\\n\\nSummary: In software engineering, continuous integration (CI) is the practice of merging all developers' working copies to a shared mainline several times a day. Nowadays it is typically implemented in such a way that it triggers an automated build with testing. Grady Booch first proposed the term CI in his 1991 method, although he did not advocate integrating several times a day. Extreme programming (XP) adopted the concept of CI and did advocate integrating more tha\\n\\n### Comparison of continuous integration software\\n\\nSummary: This is a compendium of continuous integration software that supports a software engineering practice, continuous integration, in which developers' changes are immediately tested and reported when they are added to the mainline code base. The comparison of various continuous integration tools is done on the basis of platform, license, builders and Integration IDEs.\\n\\n\\n== Features ==\\n\\n\\n== SCM system support ==\\nThe following table compares\\n\\n### Software development\\n\\nSummary: Software development is the process used to create software. Programming and maintaining the source code is the central step of this process, but it also includes conceiving the project, evaluating its feasibility, analyzing the business requirements, software design, testing, to release.  Software engineering, in addition to development, also includes \\nproject management, employee management, and other overhead functions. Software development may be sequential\\n\\n### Scrum (software development)\\n\\nSummary: Scrum is an agile team collaboration framework commonly used in software development and other industries. \\nScrum prescribes for teams to break work into goals to be completed within time-boxed iterations, called sprints. Each sprint is no longer than one month and commonly lasts two weeks. The scrum team assesses progress in time-boxed, stand-up meetings of up to 15 minutes, called daily scrums. At the end of the sprint, the team holds two further meet\\n\\n### Virtualization\\n\\nSummary: In computing, virtualization or virtualisation in British English (sometimes abbreviated v12n, a numeronym) is the act of creating a virtual (rather than actual) version of something at the same abstraction level, including virtual computer hardware platforms, storage devices, and computer network resources.\\nVirtualization began in the 1960s, as a method of logically dividing the system resources provided by mainframe computers between different applications. An earl\\n\\n### X86 virtualization\\n\\nSummary: x86 virtualization is the use of hardware-assisted virtualization capabilities on an x86/x86-64 CPU.\\nIn the late 1990s x86 virtualization was achieved by complex software techniques, necessary to compensate for the processor's lack of hardware-assisted virtualization capabilities while attaining reasonable performance. In 2005 and 2006, both Intel (VT-x) and AMD (AMD-V) introduced limited hardware virtualization support that allowed simpler virtualization softwar\\n\\n### Microservices\\n\\nSummary: In software engineering, a microservice architecture is a variant of the service-oriented architecture structural style. It is an architectural pattern that arranges an application as a collection of loosely coupled, fine-grained services, communicating through lightweight protocols. One of its goals is that teams can develop and deploy their services independently of others. This is achieved by the reduction of several dependencies in the code base, allowing develope\\n\\n### Service-oriented architecture\\n\\nSummary: In software engineering, service-oriented architecture (SOA) is an architectural style that focuses on discrete services instead of a monolithic design. By consequence, it is also applied in the field of software design where services are provided to the other components by application components, through a communication protocol over a network. A service is a discrete unit of functionality that can be accessed remotely and acted upon and updated indep\", 'interview_config': None, 'perspectives': {'editors': [{'name': 'Alice', 'role': 'Software Engineer', 'affiliation': 'Software Development Company', 'description': 'Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.'}, {'name': 'Bob', 'role': 'DevOps Specialist', 'affiliation': 'Technology Consulting Firm', 'description': 'Bob specializes in DevOps practices and will provide guidance on integrating Docker compose and local Docker labs into the DevOps pipeline. He will focus on automation, scalability, and the overall impact on the software development lifecycle.'}, {'name': 'Charlie', 'role': 'Cloud Architect', 'affiliation': 'Cloud Computing Provider', 'description': 'Charlie will offer insights on how Docker compose and local Docker labs can be effectively utilized in cloud environments. He will focus on scalability, security considerations, and the orchestration of containers for large-scale projects.'}, {'name': 'Diana', 'role': 'Open Source Contributor', 'affiliation': 'Open Source Community', 'description': 'Diana is an active contributor to open source projects related to Docker and containerization. She will focus on the community-driven aspects of using Docker compose and local Docker labs, including collaboration, sharing knowledge, and contributing to the ecosystem.'}, {'name': 'Eve', 'role': 'Researcher', 'affiliation': 'Academic Institution', 'description': 'Eve conducts research on software development methodologies and tools. She will provide insights into the theoretical foundations behind using Docker compose and local Docker labs to enhance productivity, including academic perspectives, case studies, and future trends.'}]}, 'conversations': {-6582143585576173954: ({'name': 'Alice', 'role': 'Software Engineer', 'affiliation': 'Software Development Company', 'description': 'Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.'}, {'interview_config': None, 'editor': {'name': 'Alice', 'role': 'Software Engineer', 'affiliation': 'Software Development Company', 'description': 'Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.'}, 'messages': [], 'references': {}}), 4155289580560050805: ({'name': 'Bob', 'role': 'DevOps Specialist', 'affiliation': 'Technology Consulting Firm', 'description': 'Bob specializes in DevOps practices and will provide guidance on integrating Docker compose and local Docker labs into the DevOps pipeline. He will focus on automation, scalability, and the overall impact on the software development lifecycle.'}, {'interview_config': None, 'editor': {'name': 'Bob', 'role': 'DevOps Specialist', 'affiliation': 'Technology Consulting Firm', 'description': 'Bob specializes in DevOps practices and will provide guidance on integrating Docker compose and local Docker labs into the DevOps pipeline. He will focus on automation, scalability, and the overall impact on the software development lifecycle.'}, 'messages': [], 'references': {}}), -8482578268124122984: ({'name': 'Charlie', 'role': 'Cloud Architect', 'affiliation': 'Cloud Computing Provider', 'description': 'Charlie will offer insights on how Docker compose and local Docker labs can be effectively utilized in cloud environments. He will focus on scalability, security considerations, and the orchestration of containers for large-scale projects.'}, {'interview_config': None, 'editor': {'name': 'Charlie', 'role': 'Cloud Architect', 'affiliation': 'Cloud Computing Provider', 'description': 'Charlie will offer insights on how Docker compose and local Docker labs can be effectively utilized in cloud environments. He will focus on scalability, security considerations, and the orchestration of containers for large-scale projects.'}, 'messages': [], 'references': {}}), -3453938431570339820: ({'name': 'Diana', 'role': 'Open Source Contributor', 'affiliation': 'Open Source Community', 'description': 'Diana is an active contributor to open source projects related to Docker and containerization. She will focus on the community-driven aspects of using Docker compose and local Docker labs, including collaboration, sharing knowledge, and contributing to the ecosystem.'}, {'interview_config': None, 'editor': {'name': 'Diana', 'role': 'Open Source Contributor', 'affiliation': 'Open Source Community', 'description': 'Diana is an active contributor to open source projects related to Docker and containerization. She will focus on the community-driven aspects of using Docker compose and local Docker labs, including collaboration, sharing knowledge, and contributing to the ecosystem.'}, 'messages': [], 'references': {}}), 4656673729377583323: ({'name': 'Eve', 'role': 'Researcher', 'affiliation': 'Academic Institution', 'description': 'Eve conducts research on software development methodologies and tools. She will provide insights into the theoretical foundations behind using Docker compose and local Docker labs to enhance productivity, including academic perspectives, case studies, and future trends.'}, {'interview_config': None, 'editor': {'name': 'Eve', 'role': 'Researcher', 'affiliation': 'Academic Institution', 'description': 'Eve conducts research on software development methodologies and tools. She will provide insights into the theoretical foundations behind using Docker compose and local Docker labs to enhance productivity, including academic perspectives, case studies, and future trends.'}, 'messages': [], 'references': {}})}}\n",
      "\n",
      "=======================\n",
      "Saved data to interviews.json\n",
      "Interviews saved to interviews.json\n",
      "\n",
      "-- Generated 5 perspectives for Topic: [Increase development productivity by using Docker compose and local docker labs] --\n",
      "\n",
      "\n",
      "\n",
      "***\n",
      "{-6582143585576173954: ({'name': 'Alice', 'role': 'Software Engineer', 'affiliation': 'Software Development Company', 'description': 'Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.'}, {'interview_config': {'long_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11c149490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11c17c690>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''), 'fast_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ad34e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11abfc990>, openai_api_key=SecretStr('**********'), openai_proxy=''), 'max_conversations': 3, 'max_reference_length': 10000, 'tags_to_extract': ['p', 'h1', 'h2', 'h3'], 'embeddings': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x11c17d7d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11c1a0810>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None), 'vectorstore_dir': './data/storm/vectorstore/', 'vectorstore': <langchain_community.vectorstores.chroma.Chroma object at 0x11c17c910>, 'interview_graph': None, 'runnable_config': {}}, 'editor': {'name': 'Alice', 'role': 'Software Engineer', 'affiliation': 'Software Development Company', 'description': 'Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.'}, 'messages': [], 'references': {}}), 4155289580560050805: ({'name': 'Bob', 'role': 'DevOps Specialist', 'affiliation': 'Technology Consulting Firm', 'description': 'Bob specializes in DevOps practices and will provide guidance on integrating Docker compose and local Docker labs into the DevOps pipeline. He will focus on automation, scalability, and the overall impact on the software development lifecycle.'}, {'interview_config': {'long_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11c149490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11c17c690>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''), 'fast_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ad34e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11abfc990>, openai_api_key=SecretStr('**********'), openai_proxy=''), 'max_conversations': 3, 'max_reference_length': 10000, 'tags_to_extract': ['p', 'h1', 'h2', 'h3'], 'embeddings': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x11c17d7d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11c1a0810>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None), 'vectorstore_dir': './data/storm/vectorstore/', 'vectorstore': <langchain_community.vectorstores.chroma.Chroma object at 0x11c17c910>, 'interview_graph': None, 'runnable_config': {}}, 'editor': {'name': 'Bob', 'role': 'DevOps Specialist', 'affiliation': 'Technology Consulting Firm', 'description': 'Bob specializes in DevOps practices and will provide guidance on integrating Docker compose and local Docker labs into the DevOps pipeline. He will focus on automation, scalability, and the overall impact on the software development lifecycle.'}, 'messages': [], 'references': {}}), -8482578268124122984: ({'name': 'Charlie', 'role': 'Cloud Architect', 'affiliation': 'Cloud Computing Provider', 'description': 'Charlie will offer insights on how Docker compose and local Docker labs can be effectively utilized in cloud environments. He will focus on scalability, security considerations, and the orchestration of containers for large-scale projects.'}, {'interview_config': {'long_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11c149490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11c17c690>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''), 'fast_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ad34e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11abfc990>, openai_api_key=SecretStr('**********'), openai_proxy=''), 'max_conversations': 3, 'max_reference_length': 10000, 'tags_to_extract': ['p', 'h1', 'h2', 'h3'], 'embeddings': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x11c17d7d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11c1a0810>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None), 'vectorstore_dir': './data/storm/vectorstore/', 'vectorstore': <langchain_community.vectorstores.chroma.Chroma object at 0x11c17c910>, 'interview_graph': None, 'runnable_config': {}}, 'editor': {'name': 'Charlie', 'role': 'Cloud Architect', 'affiliation': 'Cloud Computing Provider', 'description': 'Charlie will offer insights on how Docker compose and local Docker labs can be effectively utilized in cloud environments. He will focus on scalability, security considerations, and the orchestration of containers for large-scale projects.'}, 'messages': [], 'references': {}}), -3453938431570339820: ({'name': 'Diana', 'role': 'Open Source Contributor', 'affiliation': 'Open Source Community', 'description': 'Diana is an active contributor to open source projects related to Docker and containerization. She will focus on the community-driven aspects of using Docker compose and local Docker labs, including collaboration, sharing knowledge, and contributing to the ecosystem.'}, {'interview_config': {'long_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11c149490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11c17c690>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''), 'fast_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ad34e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11abfc990>, openai_api_key=SecretStr('**********'), openai_proxy=''), 'max_conversations': 3, 'max_reference_length': 10000, 'tags_to_extract': ['p', 'h1', 'h2', 'h3'], 'embeddings': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x11c17d7d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11c1a0810>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None), 'vectorstore_dir': './data/storm/vectorstore/', 'vectorstore': <langchain_community.vectorstores.chroma.Chroma object at 0x11c17c910>, 'interview_graph': None, 'runnable_config': {}}, 'editor': {'name': 'Diana', 'role': 'Open Source Contributor', 'affiliation': 'Open Source Community', 'description': 'Diana is an active contributor to open source projects related to Docker and containerization. She will focus on the community-driven aspects of using Docker compose and local Docker labs, including collaboration, sharing knowledge, and contributing to the ecosystem.'}, 'messages': [], 'references': {}}), 4656673729377583323: ({'name': 'Eve', 'role': 'Researcher', 'affiliation': 'Academic Institution', 'description': 'Eve conducts research on software development methodologies and tools. She will provide insights into the theoretical foundations behind using Docker compose and local Docker labs to enhance productivity, including academic perspectives, case studies, and future trends.'}, {'interview_config': {'long_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11c149490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11c17c690>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''), 'fast_llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ad34e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11abfc990>, openai_api_key=SecretStr('**********'), openai_proxy=''), 'max_conversations': 3, 'max_reference_length': 10000, 'tags_to_extract': ['p', 'h1', 'h2', 'h3'], 'embeddings': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x11c17d7d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11c1a0810>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None), 'vectorstore_dir': './data/storm/vectorstore/', 'vectorstore': <langchain_community.vectorstores.chroma.Chroma object at 0x11c17c910>, 'interview_graph': None, 'runnable_config': {}}, 'editor': {'name': 'Eve', 'role': 'Researcher', 'affiliation': 'Academic Institution', 'description': 'Eve conducts research on software development methodologies and tools. She will provide insights into the theoretical foundations behind using Docker compose and local Docker labs to enhance productivity, including academic perspectives, case studies, and future trends.'}, 'messages': [], 'references': {}})}\n",
      "***\n",
      "\n",
      "\n",
      "InterviewState.from_dict: data is an instance of dict\n",
      "\n",
      "\n",
      "===============\n",
      "Running interview [1/5] for Alice - Name: Alice\n",
      "Role: Software Engineer\n",
      "Affiliation: Software Development Company\n",
      "Description: Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:10,403 [MainThread  ] [INFO ]  Generated question for Alice: What are some common challenges that developers face when using Docker compose in their development workflow?\n",
      "2024-04-21 17:32:10,425 [MainThread  ] [INFO ]  START - Generate answers for [Alice]\n",
      "2024-04-21 17:32:10,946 [MainThread  ] [INFO ]  Got 1 search engine queries for [Alice] -\n",
      "\t ['Common challenges when using Docker compose in development workflow']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [Common challenges when using Docker compose in development workflow]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:12,356 [MainThread  ] [INFO ]  Got 1 search engine results for [Alice] - \n",
      "\t {'https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179': 'docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...', 'https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/': 'Five Challenges with Developing Locally Using Docker Compose. After the popularization of containers, a lot of the development workflow started leaning on Docker Compose. Developers would have a Docker Compose file which defined how to build the container images for all their services, what ports to expose, and have volumes attached to their ...', 'https://harsh05.medium.com/mastering-docker-a-guide-to-common-practical-challenges-5275c1dbfe3b': 'Expose port 80 to 1234 . Go to the word press application with the private IP address . Connect the MySQL database to the Word Press application . Create a user with the username \"Learner\" & password \"Docker\" . Create a blog with the title \"I love Docker \" . Remove the container \"Word_press\" & \"DataBase\" .', 'https://bomberbot.com/docker/mastering-docker-based-development-enabling-live-reload-for-lightning-fast-iterations/': 'Step 4: Simplifying with docker-compose. Using the docker run command works well, but it can be verbose and difficult to remember all the options. We can simplify the process by using docker-compose, a tool for defining and managing multi-container Docker applications. Create a docker-compose.yml file with the following contents:', 'https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc': \"Docker Compose uses a declarative approach to configuration, meaning you specify what you want your application's environment to look like rather than scripting the steps to get there.\"}\n",
      "2024-04-21 17:32:12,358 [MainThread  ] [INFO ]  Dumped 1934 characters for [Alice] - \n",
      "\t {\"https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\": \"docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...\", \"https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\": \"Five Challenges with Developing Locally Using Docker Compose. After the popularization of containers, a lot of the development workflow started leaning on Docker Compose. Developers would have a Docker Compose file which defined how to build the container images for all their services, what ports to expose, and have volumes attached to their ...\", \"https://harsh05.medium.com/mastering-docker-a-guide-to-common-practical-challenges-5275c1dbfe3b\": \"Expose port 80 to 1234 . Go to the word press application with the private IP address . Connect the MySQL database to the Word Press application . Create a user with the username \\\"Learner\\\" & password \\\"Docker\\\" . Create a blog with the title \\\"I love Docker \\\" . Remove the container \\\"Word_press\\\" & \\\"DataBase\\\" .\", \"https://bomberbot.com/docker/mastering-docker-based-development-enabling-live-reload-for-lightning-fast-iterations/\": \"Step 4: Simplifying with docker-compose. Using the docker run command works well, but it can be verbose and difficult to remember all the options. We can simplify the process by using docker-compose, a tool for defining and managing multi-container Docker applications. Create a docker-compose.yml file with the following contents:\", \"https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc\": \"Docker Compose uses a declarative approach to configuration, meaning you specify what you want your application's environment to look like rather than scripting the steps to get there.\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [Common challenges when using Docker compose in development workflow]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:15,733 [MainThread  ] [INFO ]  Genreted final answer answer='Some common challenges that developers face when using Docker compose in their development workflow include defining how to build container images for services, managing exposed ports, attaching volumes, connecting services like databases to applications, creating and removing containers, and dealing with the verbosity and complexity of Docker run commands. Docker Compose simplifies the management of multi-container applications by using a declarative approach to configuration, allowing developers to specify the desired application environment.' cited_urls=['https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/', 'https://bomberbot.com/docker/mastering-docker-based-development-enabling-live-reload-for-lightning-fast-iterations/', 'https://harsh05.medium.com/mastering-docker-a-guide-to-common-practical-challenges-5275c1dbfe3b', 'https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179', 'https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc'] for [Alice] - \n",
      "\t Some common challenges that developers face when using Docker compose in their development workflow include defining how to build container images for services, managing exposed ports, attaching volumes, connecting services like databases to applications, creating and removing containers, and dealing with the verbosity and complexity of Docker run commands. Docker Compose simplifies the management of multi-container applications by using a declarative approach to configuration, allowing developers to specify the desired application environment.\n",
      "\n",
      "Citations:\n",
      "\n",
      "[1]: https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\n",
      "[2]: https://bomberbot.com/docker/mastering-docker-based-development-enabling-live-reload-for-lightning-fast-iterations/\n",
      "[3]: https://harsh05.medium.com/mastering-docker-a-guide-to-common-practical-challenges-5275c1dbfe3b\n",
      "[4]: https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\n",
      "[5]: https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc\n",
      "2024-04-21 17:32:15,734 [MainThread  ] [INFO ]  END - generate answer for [Alice]\n",
      "2024-04-21 17:32:15,751 [MainThread  ] [INFO ]  Generating question for Alice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterviewState.from_dict: data is an instance of InterviewState\n",
      "Routing messages for [Alice]\n",
      "Continue asking question for [Alice] as this is not the last end of the conversation - ResponseCount: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:16,241 [MainThread  ] [INFO ]  Generated question for Alice: What are some common challenges that developers face when using Docker compose in their development workflow?\n",
      "2024-04-21 17:32:16,261 [MainThread  ] [INFO ]  START - Generate answers for [Alice]\n",
      "2024-04-21 17:32:16,759 [MainThread  ] [INFO ]  Got 1 search engine queries for [Alice] -\n",
      "\t ['Common challenges when using Docker compose in development workflow']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [Common challenges when using Docker compose in development workflow]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:18,089 [MainThread  ] [INFO ]  Got 1 search engine results for [Alice] - \n",
      "\t {'https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/': 'Five Challenges with Developing Locally Using Docker Compose. After the popularization of containers, a lot of the development workflow started leaning on Docker Compose. Developers would have a Docker Compose file which defined how to build the container images for all their services, what ports to expose, and have volumes attached to their ...', 'https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179': 'docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...', 'https://blog.devops.dev/docker-compose-tips-tricks-you-should-know-32859b6a9bee': \"The software development world would be a fundamentally different place without Docker. This is why it's important to know the basics not only of Docker, but also one of its most useful modules: Compose. Docker Compose is a way to build and run many different Docker elements together as one cohesive sytem. You can define containers, networks ...\", 'https://medium.com/@josephsims1/revolutionizing-development-workflow-with-dev-containers-0f5db53e37c4': 'The Dev Container File. Our Dev Container file is the heart of this new workflow. It outlines the specifics of the development environment, including the Docker Compose file, service ...', 'https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc': \"Docker Compose uses a declarative approach to configuration, meaning you specify what you want your application's environment to look like rather than scripting the steps to get there.\"}\n",
      "2024-04-21 17:32:18,089 [MainThread  ] [INFO ]  Dumped 1789 characters for [Alice] - \n",
      "\t {\"https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\": \"Five Challenges with Developing Locally Using Docker Compose. After the popularization of containers, a lot of the development workflow started leaning on Docker Compose. Developers would have a Docker Compose file which defined how to build the container images for all their services, what ports to expose, and have volumes attached to their ...\", \"https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\": \"docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...\", \"https://blog.devops.dev/docker-compose-tips-tricks-you-should-know-32859b6a9bee\": \"The software development world would be a fundamentally different place without Docker. This is why it's important to know the basics not only of Docker, but also one of its most useful modules: Compose. Docker Compose is a way to build and run many different Docker elements together as one cohesive sytem. You can define containers, networks ...\", \"https://medium.com/@josephsims1/revolutionizing-development-workflow-with-dev-containers-0f5db53e37c4\": \"The Dev Container File. Our Dev Container file is the heart of this new workflow. It outlines the specifics of the development environment, including the Docker Compose file, service ...\", \"https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc\": \"Docker Compose uses a declarative approach to configuration, meaning you specify what you want your application's environment to look like rather than scripting the steps to get there.\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [Common challenges when using Docker compose in development workflow]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:20,996 [MainThread  ] [INFO ]  Genreted final answer answer='Some common challenges that developers face when using Docker compose in their development workflow include defining how to build container images for services, managing exposed ports, and attaching volumes. Docker Compose simplifies the management of multiple Docker elements by allowing developers to define containers, networks, and services as one cohesive system. Additionally, Docker Compose uses a declarative approach to configuration, enabling developers to specify the desired application environment without scripting each step.' cited_urls=['https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/', 'https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179', 'https://blog.devops.dev/docker-compose-tips-tricks-you-should-know-32859b6a9bee', 'https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc'] for [Alice] - \n",
      "\t Some common challenges that developers face when using Docker compose in their development workflow include defining how to build container images for services, managing exposed ports, and attaching volumes. Docker Compose simplifies the management of multiple Docker elements by allowing developers to define containers, networks, and services as one cohesive system. Additionally, Docker Compose uses a declarative approach to configuration, enabling developers to specify the desired application environment without scripting each step.\n",
      "\n",
      "Citations:\n",
      "\n",
      "[1]: https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\n",
      "[2]: https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\n",
      "[3]: https://blog.devops.dev/docker-compose-tips-tricks-you-should-know-32859b6a9bee\n",
      "[4]: https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc\n",
      "2024-04-21 17:32:20,997 [MainThread  ] [INFO ]  END - generate answer for [Alice]\n",
      "2024-04-21 17:32:21,013 [MainThread  ] [INFO ]  Generating question for Alice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterviewState.from_dict: data is an instance of InterviewState\n",
      "Routing messages for [Alice]\n",
      "Continue asking question for [Alice] as this is not the last end of the conversation - ResponseCount: 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:21,556 [MainThread  ] [INFO ]  Generated question for Alice: What are some common challenges that developers face when using Docker compose for local development environments?\n",
      "2024-04-21 17:32:21,577 [MainThread  ] [INFO ]  START - Generate answers for [Alice]\n",
      "2024-04-21 17:32:22,000 [MainThread  ] [INFO ]  Got 1 search engine queries for [Alice] -\n",
      "\t ['Common challenges when using Docker compose for local development environments']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [Common challenges when using Docker compose for local development environments]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:23,324 [MainThread  ] [INFO ]  Got 1 search engine results for [Alice] - \n",
      "\t {'https://medium.com/simform-engineering/setting-up-a-local-development-environment-using-docker-compose-551efb4ec0ee': 'May 4, 2023. 2. Setting up a local development environment using Docker Compose. Docker Compose is a handy tool that helps you create and run applications that use multiple containers. It makes ...', 'https://reintech.io/blog/leveraging-docker-compose-local-dev-environments': 'Advantages of Using Docker Compose in Development. Consistency: Docker Compose ensures that developers are working in an environment that matches production. Ease of use: With just a few commands, new team members can get started without having to set up complex environments. Isolation: Each service runs in its own container, which minimizes ...', 'https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/': 'Consequently, developing locally with Docker Compose means working in an environment that deviates from production. This discrepancy increases the likelihood of bugs that are difficult to identify, such as misspelt environment variables or other similar issues. To ensure stability and avoid unexpected surprises upon deployment, it is crucial to ...', 'https://devcenter.heroku.com/articles/local-development-with-docker-compose': 'You can use Docker Compose to define your local development environment, including environment variables, ports that you need accessible, and volumes to mount. You define everything in docker-compose.yml, which the docker-compose CLI uses. The docker-compose.yml for the application is:', 'https://dev.to/theramoliya/docker-utilize-docker-compose-for-local-development-environments-17di': 'Here are some benefits of using Docker Compose for local development: Consistency: Docker Compose ensures that all team members use the same development environment, reducing \"it works on my machine\" issues. Isolation: Each service runs in its own container, isolating dependencies and avoiding conflicts between different components.'}\n",
      "2024-04-21 17:32:23,325 [MainThread  ] [INFO ]  Dumped 2004 characters for [Alice] - \n",
      "\t {\"https://medium.com/simform-engineering/setting-up-a-local-development-environment-using-docker-compose-551efb4ec0ee\": \"May 4, 2023. 2. Setting up a local development environment using Docker Compose. Docker Compose is a handy tool that helps you create and run applications that use multiple containers. It makes ...\", \"https://reintech.io/blog/leveraging-docker-compose-local-dev-environments\": \"Advantages of Using Docker Compose in Development. Consistency: Docker Compose ensures that developers are working in an environment that matches production. Ease of use: With just a few commands, new team members can get started without having to set up complex environments. Isolation: Each service runs in its own container, which minimizes ...\", \"https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\": \"Consequently, developing locally with Docker Compose means working in an environment that deviates from production. This discrepancy increases the likelihood of bugs that are difficult to identify, such as misspelt environment variables or other similar issues. To ensure stability and avoid unexpected surprises upon deployment, it is crucial to ...\", \"https://devcenter.heroku.com/articles/local-development-with-docker-compose\": \"You can use Docker Compose to define your local development environment, including environment variables, ports that you need accessible, and volumes to mount. You define everything in docker-compose.yml, which the docker-compose CLI uses. The docker-compose.yml for the application is:\", \"https://dev.to/theramoliya/docker-utilize-docker-compose-for-local-development-environments-17di\": \"Here are some benefits of using Docker Compose for local development: Consistency: Docker Compose ensures that all team members use the same development environment, reducing \\\"it works on my machine\\\" issues. Isolation: Each service runs in its own container, isolating dependencies and avoiding conflicts between different components.\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [Common challenges when using Docker compose for local development environments]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:30,581 [MainThread  ] [INFO ]  Genreted final answer answer='Some common challenges that developers face when using Docker Compose for local development environments include working in an environment that deviates from production, which can lead to bugs that are challenging to identify, such as misspelled environment variables. To ensure stability and avoid surprises during deployment, it is crucial to address these discrepancies. Docker Compose offers advantages such as consistency in development environments, ease of use for new team members, isolation of services in their containers to minimize conflicts, and the ability to define the local development environment with environment variables, accessible ports, and mounted volumes.' cited_urls=['https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/', 'https://reintech.io/blog/leveraging-docker-compose-local-dev-environments', 'https://dev.to/theramoliya/docker-utilize-docker-compose-for-local-development-environments-17di', 'https://devcenter.heroku.com/articles/local-development-with-docker-compose', 'https://medium.com/simform-engineering/setting-up-a-local-development-environment-using-docker-compose-551efb4ec0ee'] for [Alice] - \n",
      "\t Some common challenges that developers face when using Docker Compose for local development environments include working in an environment that deviates from production, which can lead to bugs that are challenging to identify, such as misspelled environment variables. To ensure stability and avoid surprises during deployment, it is crucial to address these discrepancies. Docker Compose offers advantages such as consistency in development environments, ease of use for new team members, isolation of services in their containers to minimize conflicts, and the ability to define the local development environment with environment variables, accessible ports, and mounted volumes.\n",
      "\n",
      "Citations:\n",
      "\n",
      "[1]: https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\n",
      "[2]: https://reintech.io/blog/leveraging-docker-compose-local-dev-environments\n",
      "[3]: https://dev.to/theramoliya/docker-utilize-docker-compose-for-local-development-environments-17di\n",
      "[4]: https://devcenter.heroku.com/articles/local-development-with-docker-compose\n",
      "[5]: https://medium.com/simform-engineering/setting-up-a-local-development-environment-using-docker-compose-551efb4ec0ee\n",
      "2024-04-21 17:32:30,582 [MainThread  ] [INFO ]  END - generate answer for [Alice]\n",
      "2024-04-21 17:32:30,607 [MainThread  ] [INFO ]  Generating question for Bob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterviewState.from_dict: data is an instance of InterviewState\n",
      "Routing messages for [Alice]\n",
      "Reached max number of responses for [Alice] - ResponseCount: 3\n",
      "InterviewState.from_dict: data is an instance of dict\n",
      "InterviewState(interview_config=InterviewConfig(long_llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11c149490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11c17c690>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''), fast_llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11ad34e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11abfc990>, openai_api_key=SecretStr('**********'), openai_proxy=''), max_conversations=3, max_reference_length=10000, tags_to_extract=['p', 'h1', 'h2', 'h3'], embeddings=OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x11c17d7d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11c1a0810>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None), vectorstore_dir='./data/storm/vectorstore/', vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x11c17c910>, interview_graph=<storm.StormInterviewGraph1 object at 0x11dee4e90>, runnable_config={}), editor={'name': 'Alice', 'role': 'Software Engineer', 'affiliation': 'Software Development Company', 'description': 'Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.'}, messages=[HumanMessage(content='What are some common challenges that developers face when using Docker compose in their development workflow?', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 197, 'total_tokens': 214}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, name='Alice', id='run-306bd919-1848-4990-92b0-793c7995635b-0', invalid_tool_calls=[], tool_calls=[]), AIMessage(content='{\"queries\": [\"Common challenges when using Docker compose in development workflow\"]}', name='AI'), HumanMessage(content='{\"https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\": \"docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...\", \"https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\": \"Five Challenges with Developing Locally Using Docker Compose. After the popularization of containers, a lot of the development workflow started leaning on Docker Compose. Developers would have a Docker Compose file which defined how to build the container images for all their services, what ports to expose, and have volumes attached to their ...\", \"https://harsh05.medium.com/mastering-docker-a-guide-to-common-practical-challenges-5275c1dbfe3b\": \"Expose port 80 to 1234 . Go to the word press application with the private IP address . Connect the MySQL database to the Word Press application . Create a user with the username \\\\\"Learner\\\\\" & password \\\\\"Docker\\\\\" . Create a blog with the title \\\\\"I love Docker \\\\\" . Remove the container \\\\\"Word_press\\\\\" & \\\\\"DataBase\\\\\" .\", \"https://bomberbot.com/docker/mastering-docker-based-development-enabling-live-reload-for-lightning-fast-iterations/\": \"Step 4: Simplifying with docker-compose. Using the docker run command works well, but it can be verbose and difficult to remember all the options. We can simplify the process by using docker-compose, a tool for defining and managing multi-container Docker applications. Create a docker-compose.yml file with the following contents:\", \"https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc\": \"Docker Compose uses a declarative approach to configuration, meaning you specify what you want your application\\'s environment to look like rather than scripting the steps to get there.\"}'), AIMessage(content='Some common challenges that developers face when using Docker compose in their development workflow include defining how to build container images for services, managing exposed ports, attaching volumes, connecting services like databases to applications, creating and removing containers, and dealing with the verbosity and complexity of Docker run commands. Docker Compose simplifies the management of multi-container applications by using a declarative approach to configuration, allowing developers to specify the desired application environment.\\n\\nCitations:\\n\\n[1]: https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\\n[2]: https://bomberbot.com/docker/mastering-docker-based-development-enabling-live-reload-for-lightning-fast-iterations/\\n[3]: https://harsh05.medium.com/mastering-docker-a-guide-to-common-practical-challenges-5275c1dbfe3b\\n[4]: https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\\n[5]: https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc', name='Alice'), HumanMessage(content='What are some common challenges that developers face when using Docker compose in their development workflow?', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 197, 'total_tokens': 214}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, name='Alice', id='run-cf3f90a3-82dc-411a-81e5-32d273e20be4-0', invalid_tool_calls=[], tool_calls=[]), AIMessage(content='{\"queries\": [\"Common challenges when using Docker compose in development workflow\"]}', name='AI'), HumanMessage(content='{\"https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\": \"Five Challenges with Developing Locally Using Docker Compose. After the popularization of containers, a lot of the development workflow started leaning on Docker Compose. Developers would have a Docker Compose file which defined how to build the container images for all their services, what ports to expose, and have volumes attached to their ...\", \"https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\": \"docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...\", \"https://blog.devops.dev/docker-compose-tips-tricks-you-should-know-32859b6a9bee\": \"The software development world would be a fundamentally different place without Docker. This is why it\\'s important to know the basics not only of Docker, but also one of its most useful modules: Compose. Docker Compose is a way to build and run many different Docker elements together as one cohesive sytem. You can define containers, networks ...\", \"https://medium.com/@josephsims1/revolutionizing-development-workflow-with-dev-containers-0f5db53e37c4\": \"The Dev Container File. Our Dev Container file is the heart of this new workflow. It outlines the specifics of the development environment, including the Docker Compose file, service ...\", \"https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc\": \"Docker Compose uses a declarative approach to configuration, meaning you specify what you want your application\\'s environment to look like rather than scripting the steps to get there.\"}'), AIMessage(content='Some common challenges that developers face when using Docker compose in their development workflow include defining how to build container images for services, managing exposed ports, and attaching volumes. Docker Compose simplifies the management of multiple Docker elements by allowing developers to define containers, networks, and services as one cohesive system. Additionally, Docker Compose uses a declarative approach to configuration, enabling developers to specify the desired application environment without scripting each step.\\n\\nCitations:\\n\\n[1]: https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\\n[2]: https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\\n[3]: https://blog.devops.dev/docker-compose-tips-tricks-you-should-know-32859b6a9bee\\n[4]: https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc', name='Alice'), HumanMessage(content='What are some common challenges that developers face when using Docker compose for local development environments?', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 197, 'total_tokens': 214}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, name='Alice', id='run-fe69940f-f340-482d-a081-a94d8cc7af87-0', invalid_tool_calls=[], tool_calls=[]), AIMessage(content='{\"queries\": [\"Common challenges when using Docker compose for local development environments\"]}', name='AI'), HumanMessage(content='{\"https://medium.com/simform-engineering/setting-up-a-local-development-environment-using-docker-compose-551efb4ec0ee\": \"May 4, 2023. 2. Setting up a local development environment using Docker Compose. Docker Compose is a handy tool that helps you create and run applications that use multiple containers. It makes ...\", \"https://reintech.io/blog/leveraging-docker-compose-local-dev-environments\": \"Advantages of Using Docker Compose in Development. Consistency: Docker Compose ensures that developers are working in an environment that matches production. Ease of use: With just a few commands, new team members can get started without having to set up complex environments. Isolation: Each service runs in its own container, which minimizes ...\", \"https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\": \"Consequently, developing locally with Docker Compose means working in an environment that deviates from production. This discrepancy increases the likelihood of bugs that are difficult to identify, such as misspelt environment variables or other similar issues. To ensure stability and avoid unexpected surprises upon deployment, it is crucial to ...\", \"https://devcenter.heroku.com/articles/local-development-with-docker-compose\": \"You can use Docker Compose to define your local development environment, including environment variables, ports that you need accessible, and volumes to mount. You define everything in docker-compose.yml, which the docker-compose CLI uses. The docker-compose.yml for the application is:\", \"https://dev.to/theramoliya/docker-utilize-docker-compose-for-local-development-environments-17di\": \"Here are some benefits of using Docker Compose for local development: Consistency: Docker Compose ensures that all team members use the same development environment, reducing \\\\\"it works on my machine\\\\\" issues. Isolation: Each service runs in its own container, isolating dependencies and avoiding conflicts between different components.\"}'), AIMessage(content='Some common challenges that developers face when using Docker Compose for local development environments include working in an environment that deviates from production, which can lead to bugs that are challenging to identify, such as misspelled environment variables. To ensure stability and avoid surprises during deployment, it is crucial to address these discrepancies. Docker Compose offers advantages such as consistency in development environments, ease of use for new team members, isolation of services in their containers to minimize conflicts, and the ability to define the local development environment with environment variables, accessible ports, and mounted volumes.\\n\\nCitations:\\n\\n[1]: https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/\\n[2]: https://reintech.io/blog/leveraging-docker-compose-local-dev-environments\\n[3]: https://dev.to/theramoliya/docker-utilize-docker-compose-for-local-development-environments-17di\\n[4]: https://devcenter.heroku.com/articles/local-development-with-docker-compose\\n[5]: https://medium.com/simform-engineering/setting-up-a-local-development-environment-using-docker-compose-551efb4ec0ee', name='Alice')], references={'https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179': 'docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...', 'https://www.okteto.com/blog/five-challenges-with-developing-locally-using-docker-compose/': 'Consequently, developing locally with Docker Compose means working in an environment that deviates from production. This discrepancy increases the likelihood of bugs that are difficult to identify, such as misspelt environment variables or other similar issues. To ensure stability and avoid unexpected surprises upon deployment, it is crucial to ...', 'https://harsh05.medium.com/mastering-docker-a-guide-to-common-practical-challenges-5275c1dbfe3b': 'Expose port 80 to 1234 . Go to the word press application with the private IP address . Connect the MySQL database to the Word Press application . Create a user with the username \"Learner\" & password \"Docker\" . Create a blog with the title \"I love Docker \" . Remove the container \"Word_press\" & \"DataBase\" .', 'https://bomberbot.com/docker/mastering-docker-based-development-enabling-live-reload-for-lightning-fast-iterations/': 'Step 4: Simplifying with docker-compose. Using the docker run command works well, but it can be verbose and difficult to remember all the options. We can simplify the process by using docker-compose, a tool for defining and managing multi-container Docker applications. Create a docker-compose.yml file with the following contents:', 'https://www.linkedin.com/pulse/empowering-development-workflows-docker-compose-suraj-kulkarni-4ivuc': \"Docker Compose uses a declarative approach to configuration, meaning you specify what you want your application's environment to look like rather than scripting the steps to get there.\", 'https://blog.devops.dev/docker-compose-tips-tricks-you-should-know-32859b6a9bee': \"The software development world would be a fundamentally different place without Docker. This is why it's important to know the basics not only of Docker, but also one of its most useful modules: Compose. Docker Compose is a way to build and run many different Docker elements together as one cohesive sytem. You can define containers, networks ...\", 'https://medium.com/simform-engineering/setting-up-a-local-development-environment-using-docker-compose-551efb4ec0ee': 'May 4, 2023. 2. Setting up a local development environment using Docker Compose. Docker Compose is a handy tool that helps you create and run applications that use multiple containers. It makes ...', 'https://reintech.io/blog/leveraging-docker-compose-local-dev-environments': 'Advantages of Using Docker Compose in Development. Consistency: Docker Compose ensures that developers are working in an environment that matches production. Ease of use: With just a few commands, new team members can get started without having to set up complex environments. Isolation: Each service runs in its own container, which minimizes ...', 'https://devcenter.heroku.com/articles/local-development-with-docker-compose': 'You can use Docker Compose to define your local development environment, including environment variables, ports that you need accessible, and volumes to mount. You define everything in docker-compose.yml, which the docker-compose CLI uses. The docker-compose.yml for the application is:', 'https://dev.to/theramoliya/docker-utilize-docker-compose-for-local-development-environments-17di': 'Here are some benefits of using Docker Compose for local development: Consistency: Docker Compose ensures that all team members use the same development environment, reducing \"it works on my machine\" issues. Isolation: Each service runs in its own container, isolating dependencies and avoiding conflicts between different components.'})\n",
      "===============\n",
      "Finished interview for Alice - Name: Alice\n",
      "Role: Software Engineer\n",
      "Affiliation: Software Development Company\n",
      "Description: Alice will focus on practical implementation examples of using Docker compose and local Docker labs to increase development productivity. She will provide insights into best practices, common challenges, and how to optimize development workflows using these tools.\n",
      "\n",
      "\n",
      "\n",
      "InterviewState.from_dict: data is an instance of dict\n",
      "\n",
      "\n",
      "===============\n",
      "Running interview [2/5] for Bob - Name: Bob\n",
      "Role: DevOps Specialist\n",
      "Affiliation: Technology Consulting Firm\n",
      "Description: Bob specializes in DevOps practices and will provide guidance on integrating Docker compose and local Docker labs into the DevOps pipeline. He will focus on automation, scalability, and the overall impact on the software development lifecycle.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:31,297 [MainThread  ] [INFO ]  Generated question for Bob: What are some best practices for integrating Docker compose and local Docker labs into the DevOps pipeline to enhance automation and scalability in software development?\n",
      "2024-04-21 17:32:31,317 [MainThread  ] [INFO ]  START - Generate answers for [Bob]\n",
      "2024-04-21 17:32:32,387 [MainThread  ] [INFO ]  Got 4 search engine queries for [Bob] -\n",
      "\t ['best practices for integrating Docker compose in DevOps pipeline', 'best practices for integrating local Docker labs in DevOps pipeline', 'how to enhance automation in software development using Docker compose', 'how to enhance scalability in software development using Docker compose']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [best practices for integrating Docker compose in DevOps pipeline]\n",
      "Got search engine results: 5 for [best practices for integrating Docker compose in DevOps pipeline]\n",
      "Searching DuckDuckGo for [best practices for integrating local Docker labs in DevOps pipeline]\n",
      "Got search engine results: 5 for [best practices for integrating local Docker labs in DevOps pipeline]\n",
      "Searching DuckDuckGo for [how to enhance automation in software development using Docker compose]\n",
      "Got search engine results: 5 for [how to enhance automation in software development using Docker compose]\n",
      "Searching DuckDuckGo for [how to enhance scalability in software development using Docker compose]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:38,674 [MainThread  ] [INFO ]  Got 4 search engine results for [Bob] - \n",
      "\t {'https://blog.devops.dev/a-deep-dive-into-docker-compose-for-devops-engineers-5b640bc47715': 'Docker Compose is a tool that makes it easier to manage the complexities of multi-container applications. Instead of managing each Docker container individually, Docker Compose allows you to define multiple containers, their configurations, networks, and volumes in a single docker-compose.yml file. With a single command, you can spin up or tear ...', 'https://reintech.io/blog/continuous-integration-workflows-docker-compose': 'In the world of software development, Continuous Integration (CI) has become an indispensable practice, allowing teams to merge their code changes into a central repository, where builds and tests are run automatically. This approach minimizes integration issues and leads to more reliable software. Docker Compose is a tool that can significantly simplify the CI process by defining and running ...', 'https://blog.devops.dev/devops-zero-to-hero-5-docker-compose-to-run-multi-container-docker-applications-f8e51db47f22': 'mkdir docker-compose cd docker-compose touch docker-compose.yml requirements.txt app.py Dockerfile mkdir -p static/css touch static/css/style.css mkdir templates touch templates/index.html. Dockerfile  This will be used to build the web application image. app.py  This will contain the Flask code for the web application we will build in ...', 'https://www.linkedin.com/pulse/mastering-docker-best-practices-devops-engineers-guide-daniel-gurus-mgtsc': \"3. Implement Docker Compose for Environment Configuration: Docker Compose is a powerful tool for defining and managing multi-container Docker applications. Use it to describe your application's ...\", 'https://blogbells.com/containerization/using-docker-in-ci-cd-how-to-improve-your-devops-pipeline/': 'Implementation Steps: Docker in a CI/CD Pipeline. Integrating Docker into your CI/CD pipeline can be achieved with the following steps. Step 1: Define your Docker Image. The first step involves defining your Docker image. This is usually done in a Dockerfile, which specifies the base image, application code, and any dependencies your ...', 'https://towardsaws.com/devops-lab-7-automating-pipeline-deployments-with-docker-b3c02ba1bccf': \"Let's start by installing Docker.In a previous lab (Improving code quality with SonarQube), we went through the process of installing Docker but it was mainly to run SonarQube inside of a container.Now we will be installing Docker on the same EC2 instance Jenkins is running on with the goal of integrating it into the pipeline.. For me to be able to do this, I had to change the EC2 instance ...\", 'https://towardsdev.com/devops-lab-10-executing-docker-deployments-via-azure-devops-166b212b5dc8': 'Docker pipeline tasks: Head back to the pipeline as we are going to add 2 more tasks. Search for docker and install both Docker and Docker CLI installer. Now we have to configure the Docker task. Click on the task then on Manage. Click on New service connection and select Docker Registry.', 'https://stackoverflow.com/questions/76349895/how-properly-run-and-use-docker-in-azure-devops-pipelines': '0. Below are the steps to execute a command on the docker image. Step 1: Create a service connection to the container registry if it is private. For public registries, a service connection is not required. Step 2: Specify the container in the resources section of the pipeline and add the service connection name as the endpoint as shown below.', 'https://reintech.io/blog/containerization-docker-azure-devops': \"This integration provides a robust environment for automating the continuous integration and deployment (CI/CD) pipeline, resulting in efficient and scalable workflows. Understanding Docker in Azure DevOps. Docker utilizes containers to encapsulate an application's code, libraries, and dependencies into a single object.\", 'https://www.appsdeveloperblog.com/docker-and-devops/': \"Choose Git in the SCM dropdown and provide the Repository URL where your code resides. In the Script Path field, provide the path to your Jenkinsfile. Run the pipeline: Save your changes and click 'Build Now' to run your pipeline. And that's it! You've successfully integrated Docker into a CI/CD pipeline.\", 'https://dev.to/docker/automated-updates-made-easy-unveiling-docker-compose-file-watch-4jgc': 'This compose file defines two services, web and mysql, and a volume named todo-mysql-data, similar to the original file.However, the web service now includes an x-develop section, which enables the experimental \"watch\" mode for this service.. The watch section contains two actions: sync and rebuild.The \"sync\" action specifies a path to watch for changes in the host file system, and a ...', 'https://blog.devgenius.io/docker-compose-complete-guide-with-hands-on-examples-c5697ec84220': 'By using Docker Compose, we can simplify the process of managing microservices, making it easier to test their functionality. To make a new file called docker-compose.yml for your project, head to the root of your project folder. This file will be used to manage the frontend and backend services of your project.', 'https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179': 'docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...', 'https://github.blog/2024-01-24-how-githubs-developer-experience-team-improved-innerloop-development/': '# Run command from inside a container in the system using Docker-Compose docker compose --project-name hcs exec bash # Run from inside a container using CLI hcs shell This example compares how to check the status of the containers in the project so end-users can easily see the health of the entire system.', 'https://www.appsdeveloperblog.com/scaling-with-docker-compose-a-beginners-guide/': 'The first step is to define our services in a docker-compose.yml file. This file will contain the configurations of our Tomcat and MySQL services. Here\\'s a simple configuration: In this file, we have two services: \"db\" and \"web\". The \"db\" service uses the official MySQL 5.7 image from Docker Hub.', 'https://dev.to/tellaboutcrypt/revolutionizing-application-deployment-and-scalability-using-docker-1mee': 'Scaling applications with Docker Swarm mode. Scaling applications using Docker Swarm and achieving a high level of availability and scalability involves proper deployment and management of a cluster of Docker nodes. Docker nodes are essentially a swarm created in swarm mode. These nodes in a swarm act as a single entity.', 'https://www.nucamp.co/blog/coding-bootcamp-back-end-with-python-and-sql-scaling-applications-with-docker-a-stepbystep-guide': 'Learn how enhanced scalability with Docker can revolutionize your back-end systems. Master the backbone of container orchestration by diving deep into Docker Compose YAML files and their crucial role in defining multi-container environments. Explore predictions for the future of Docker container security in an ever-evolving technological landscape.', 'https://dev.to/documatic/how-to-dockerize-your-application-536i': 'Copies the remaining application files from the host to the container\\'s working directory. CMD [\"npm\", \"start\"]: Specifies the command to run when the container is started, in this case, npm start to start the Node.js application. Docker Compose is a tool that simplifies the management of multi-container applications.', 'https://denisa11petric.medium.com/containerization-with-docker-simplifying-application-deployment-3338086c5f7f': 'To fully leverage the benefits of Docker containerization, here are some best practices to follow: Use lightweight base images to minimize container size and improve performance. Keep containers immutable and stateless to ensure reliability and scalability. Use Docker Compose for defining multi-container applications and managing dependencies.'}\n",
      "2024-04-21 17:32:38,675 [MainThread  ] [INFO ]  Dumped 8058 characters for [Bob] - \n",
      "\t {\"https://blog.devops.dev/a-deep-dive-into-docker-compose-for-devops-engineers-5b640bc47715\": \"Docker Compose is a tool that makes it easier to manage the complexities of multi-container applications. Instead of managing each Docker container individually, Docker Compose allows you to define multiple containers, their configurations, networks, and volumes in a single docker-compose.yml file. With a single command, you can spin up or tear ...\", \"https://reintech.io/blog/continuous-integration-workflows-docker-compose\": \"In the world of software development, Continuous Integration (CI) has become an indispensable practice, allowing teams to merge their code changes into a central repository, where builds and tests are run automatically. This approach minimizes integration issues and leads to more reliable software. Docker Compose is a tool that can significantly simplify the CI process by defining and running ...\", \"https://blog.devops.dev/devops-zero-to-hero-5-docker-compose-to-run-multi-container-docker-applications-f8e51db47f22\": \"mkdir docker-compose cd docker-compose touch docker-compose.yml requirements.txt app.py Dockerfile mkdir -p static/css touch static/css/style.css mkdir templates touch templates/index.html. Dockerfile \\u2014 This will be used to build the web application image. app.py \\u2014 This will contain the Flask code for the web application we will build in ...\", \"https://www.linkedin.com/pulse/mastering-docker-best-practices-devops-engineers-guide-daniel-gurus-mgtsc\": \"3. Implement Docker Compose for Environment Configuration: Docker Compose is a powerful tool for defining and managing multi-container Docker applications. Use it to describe your application's ...\", \"https://blogbells.com/containerization/using-docker-in-ci-cd-how-to-improve-your-devops-pipeline/\": \"Implementation Steps: Docker in a CI/CD Pipeline. Integrating Docker into your CI/CD pipeline can be achieved with the following steps. Step 1: Define your Docker Image. The first step involves defining your Docker image. This is usually done in a Dockerfile, which specifies the base image, application code, and any dependencies your ...\", \"https://towardsaws.com/devops-lab-7-automating-pipeline-deployments-with-docker-b3c02ba1bccf\": \"Let's start by installing Docker.In a previous lab (Improving code quality with SonarQube), we went through the process of installing Docker but it was mainly to run SonarQube inside of a container.Now we will be installing Docker on the same EC2 instance Jenkins is running on with the goal of integrating it into the pipeline.. For me to be able to do this, I had to change the EC2 instance ...\", \"https://towardsdev.com/devops-lab-10-executing-docker-deployments-via-azure-devops-166b212b5dc8\": \"Docker pipeline tasks: Head back to the pipeline as we are going to add 2 more tasks. Search for docker and install both Docker and Docker CLI installer. Now we have to configure the Docker task. Click on the task then on Manage. Click on New service connection and select Docker Registry.\", \"https://stackoverflow.com/questions/76349895/how-properly-run-and-use-docker-in-azure-devops-pipelines\": \"0. Below are the steps to execute a command on the docker image. Step 1: Create a service connection to the container registry if it is private. For public registries, a service connection is not required. Step 2: Specify the container in the resources section of the pipeline and add the service connection name as the endpoint as shown below.\", \"https://reintech.io/blog/containerization-docker-azure-devops\": \"This integration provides a robust environment for automating the continuous integration and deployment (CI/CD) pipeline, resulting in efficient and scalable workflows. Understanding Docker in Azure DevOps. Docker utilizes containers to encapsulate an application's code, libraries, and dependencies into a single object.\", \"https://www.appsdeveloperblog.com/docker-and-devops/\": \"Choose Git in the SCM dropdown and provide the Repository URL where your code resides. In the Script Path field, provide the path to your Jenkinsfile. Run the pipeline: Save your changes and click 'Build Now' to run your pipeline. And that's it! You've successfully integrated Docker into a CI/CD pipeline.\", \"https://dev.to/docker/automated-updates-made-easy-unveiling-docker-compose-file-watch-4jgc\": \"This compose file defines two services, web and mysql, and a volume named todo-mysql-data, similar to the original file.However, the web service now includes an x-develop section, which enables the experimental \\\"watch\\\" mode for this service.. The watch section contains two actions: sync and rebuild.The \\\"sync\\\" action specifies a path to watch for changes in the host file system, and a ...\", \"https://blog.devgenius.io/docker-compose-complete-guide-with-hands-on-examples-c5697ec84220\": \"By using Docker Compose, we can simplify the process of managing microservices, making it easier to test their functionality. To make a new file called docker-compose.yml for your project, head to the root of your project folder. This file will be used to manage the frontend and backend services of your project.\", \"https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\": \"docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...\", \"https://github.blog/2024-01-24-how-githubs-developer-experience-team-improved-innerloop-development/\": \"# Run command from inside a container in the system using Docker-Compose docker compose --project-name hcs exec bash # Run from inside a container using CLI hcs shell This example compares how to check the status of the containers in the project so end-users can easily see the health of the entire system.\", \"https://www.appsdeveloperblog.com/scaling-with-docker-compose-a-beginners-guide/\": \"The first step is to define our services in a docker-compose.yml file. This file will contain the configurations of our Tomcat and MySQL services. Here's a simple configuration: In this file, we have two services: \\\"db\\\" and \\\"web\\\". The \\\"db\\\" service uses the official MySQL 5.7 image from Docker Hub.\", \"https://dev.to/tellaboutcrypt/revolutionizing-application-deployment-and-scalability-using-docker-1mee\": \"Scaling applications with Docker Swarm mode. Scaling applications using Docker Swarm and achieving a high level of availability and scalability involves proper deployment and management of a cluster of Docker nodes. Docker nodes are essentially a swarm created in swarm mode. These nodes in a swarm act as a single entity.\", \"https://www.nucamp.co/blog/coding-bootcamp-back-end-with-python-and-sql-scaling-applications-with-docker-a-stepbystep-guide\": \"Learn how enhanced scalability with Docker can revolutionize your back-end systems. Master the backbone of container orchestration by diving deep into Docker Compose YAML files and their crucial role in defining multi-container environments. Explore predictions for the future of Docker container security in an ever-evolving technological landscape.\", \"https://dev.to/documatic/how-to-dockerize-your-application-536i\": \"Copies the remaining application files from the host to the container's working directory. CMD [\\\"npm\\\", \\\"start\\\"]: Specifies the command to run when the container is started, in this case, npm start to start the Node.js application. Docker Compose is a tool that simplifies the management of multi-container applications.\", \"https://denisa11petric.medium.com/containerization-with-docker-simplifying-application-deployment-3338086c5f7f\": \"To fully leverage the benefits of Docker containerization, here are some best practices to follow: Use lightweight base images to minimize container size and improve performance. Keep containers immutable and stateless to ensure reliability and scalability. Use Docker Compose for defining multi-container applications and managing dependencies.\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [how to enhance scalability in software development using Docker compose]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:45,411 [MainThread  ] [INFO ]  Genreted final answer answer='Integrating Docker Compose into the DevOps pipeline can greatly enhance automation and scalability in software development. Docker Compose simplifies the management of multi-container applications by allowing you to define multiple containers, configurations, networks, and volumes in a single docker-compose.yml file. This streamlines the process of spinning up or tearing down complex application environments with a single command, making it easier to manage and replicate development and testing setups. Additionally, using Docker Compose for environment configuration can help in defining and managing multi-container Docker applications efficiently. By leveraging Docker Compose, teams can enhance the Continuous Integration (CI) process, making it easier to build, test, and deploy applications automatically. This integration provides a robust environment for automating the CI/CD pipeline, leading to more efficient and scalable workflows. Following best practices such as using lightweight base images, keeping containers immutable and stateless, and defining multi-container applications with Docker Compose can further improve the reliability, performance, and scalability of software deployments.' cited_urls=['https://blog.devops.dev/a-deep-dive-into-docker-compose-for-devops-engineers-5b640bc47715', 'https://reintech.io/blog/continuous-integration-workflows-docker-compose', 'https://blog.devops.dev/devops-zero-to-hero-5-docker-compose-to-run-multi-container-docker-applications-f8e51db47f22', 'https://www.linkedin.com/pulse/mastering-docker-best-practices-devops-engineers-guide-daniel-gurus-mgtsc', 'https://blogbells.com/containerization/using-docker-in-ci-cd-how-to-improve-your-devops-pipeline/', 'https://reintech.io/blog/containerization-docker-azure-devops', 'https://www.appsdeveloperblog.com/docker-and-devops/', 'https://www.appsdeveloperblog.com/scaling-with-docker-compose-a-beginners-guide/', 'https://denisa11petric.medium.com/containerization-with-docker-simplifying-application-deployment-3338086c5f7f'] for [Bob] - \n",
      "\t Integrating Docker Compose into the DevOps pipeline can greatly enhance automation and scalability in software development. Docker Compose simplifies the management of multi-container applications by allowing you to define multiple containers, configurations, networks, and volumes in a single docker-compose.yml file. This streamlines the process of spinning up or tearing down complex application environments with a single command, making it easier to manage and replicate development and testing setups. Additionally, using Docker Compose for environment configuration can help in defining and managing multi-container Docker applications efficiently. By leveraging Docker Compose, teams can enhance the Continuous Integration (CI) process, making it easier to build, test, and deploy applications automatically. This integration provides a robust environment for automating the CI/CD pipeline, leading to more efficient and scalable workflows. Following best practices such as using lightweight base images, keeping containers immutable and stateless, and defining multi-container applications with Docker Compose can further improve the reliability, performance, and scalability of software deployments.\n",
      "\n",
      "Citations:\n",
      "\n",
      "[1]: https://blog.devops.dev/a-deep-dive-into-docker-compose-for-devops-engineers-5b640bc47715\n",
      "[2]: https://reintech.io/blog/continuous-integration-workflows-docker-compose\n",
      "[3]: https://blog.devops.dev/devops-zero-to-hero-5-docker-compose-to-run-multi-container-docker-applications-f8e51db47f22\n",
      "[4]: https://www.linkedin.com/pulse/mastering-docker-best-practices-devops-engineers-guide-daniel-gurus-mgtsc\n",
      "[5]: https://blogbells.com/containerization/using-docker-in-ci-cd-how-to-improve-your-devops-pipeline/\n",
      "[6]: https://reintech.io/blog/containerization-docker-azure-devops\n",
      "[7]: https://www.appsdeveloperblog.com/docker-and-devops/\n",
      "[8]: https://www.appsdeveloperblog.com/scaling-with-docker-compose-a-beginners-guide/\n",
      "[9]: https://denisa11petric.medium.com/containerization-with-docker-simplifying-application-deployment-3338086c5f7f\n",
      "2024-04-21 17:32:45,412 [MainThread  ] [INFO ]  END - generate answer for [Bob]\n",
      "2024-04-21 17:32:45,428 [MainThread  ] [INFO ]  Generating question for Bob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterviewState.from_dict: data is an instance of InterviewState\n",
      "Routing messages for [Bob]\n",
      "Continue asking question for [Bob] as this is not the last end of the conversation - ResponseCount: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:46,034 [MainThread  ] [INFO ]  Generated question for Bob: What are some best practices for integrating Docker compose and local Docker labs into the DevOps pipeline to ensure automation and scalability in the software development lifecycle?\n",
      "2024-04-21 17:32:46,055 [MainThread  ] [INFO ]  START - Generate answers for [Bob]\n",
      "2024-04-21 17:32:46,987 [MainThread  ] [INFO ]  Got 4 search engine queries for [Bob] -\n",
      "\t ['best practices for integrating Docker compose in DevOps pipeline', 'best practices for integrating local Docker labs in DevOps pipeline', 'how to ensure automation in software development using Docker compose', 'how to ensure scalability in software development using Docker compose']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching DuckDuckGo for [best practices for integrating Docker compose in DevOps pipeline]\n",
      "Got search engine results: 5 for [best practices for integrating Docker compose in DevOps pipeline]\n",
      "Searching DuckDuckGo for [best practices for integrating local Docker labs in DevOps pipeline]\n",
      "Got search engine results: 5 for [best practices for integrating local Docker labs in DevOps pipeline]\n",
      "Searching DuckDuckGo for [how to ensure automation in software development using Docker compose]\n",
      "Got search engine results: 5 for [how to ensure automation in software development using Docker compose]\n",
      "Searching DuckDuckGo for [how to ensure scalability in software development using Docker compose]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 17:32:52,766 [MainThread  ] [INFO ]  Got 4 search engine results for [Bob] - \n",
      "\t {'https://blog.devops.dev/a-deep-dive-into-docker-compose-for-devops-engineers-5b640bc47715': 'Docker Compose is a tool that makes it easier to manage the complexities of multi-container applications. Instead of managing each Docker container individually, Docker Compose allows you to define multiple containers, their configurations, networks, and volumes in a single docker-compose.yml file. With a single command, you can spin up or tear ...', 'https://blog.devops.dev/devops-zero-to-hero-5-docker-compose-to-run-multi-container-docker-applications-f8e51db47f22': 'mkdir docker-compose cd docker-compose touch docker-compose.yml requirements.txt app.py Dockerfile mkdir -p static/css touch static/css/style.css mkdir templates touch templates/index.html. Dockerfile  This will be used to build the web application image. app.py  This will contain the Flask code for the web application we will build in ...', 'https://reintech.io/blog/continuous-integration-workflows-docker-compose': 'In the world of software development, Continuous Integration (CI) has become an indispensable practice, allowing teams to merge their code changes into a central repository, where builds and tests are run automatically. This approach minimizes integration issues and leads to more reliable software. Docker Compose is a tool that can significantly simplify the CI process by defining and running ...', 'https://medium.com/@daithimassey/how-to-set-up-a-devops-pipeline-from-scratch-a-comprehensive-guide-308763205462': \"Initialize a New Repository. Clone an Existing Repository. Basic Git Workflow. Here's a simplified workflow to give you an idea of how to work with Git: 1. Create a New Branch: Always create a ...\", 'https://blogbells.com/containerization/using-docker-in-ci-cd-how-to-improve-your-devops-pipeline/': 'Implementation Steps: Docker in a CI/CD Pipeline. Integrating Docker into your CI/CD pipeline can be achieved with the following steps. Step 1: Define your Docker Image. The first step involves defining your Docker image. This is usually done in a Dockerfile, which specifies the base image, application code, and any dependencies your ...', 'https://stackoverflow.com/questions/76349895/how-properly-run-and-use-docker-in-azure-devops-pipelines': '0. Below are the steps to execute a command on the docker image. Step 1: Create a service connection to the container registry if it is private. For public registries, a service connection is not required. Step 2: Specify the container in the resources section of the pipeline and add the service connection name as the endpoint as shown below.', 'https://towardsdev.com/devops-lab-10-executing-docker-deployments-via-azure-devops-166b212b5dc8': 'Docker pipeline tasks: Head back to the pipeline as we are going to add 2 more tasks. Search for docker and install both Docker and Docker CLI installer. Now we have to configure the Docker task. Click on the task then on Manage. Click on New service connection and select Docker Registry.', 'https://towardsaws.com/devops-lab-7-automating-pipeline-deployments-with-docker-b3c02ba1bccf': \"Let's start by installing Docker.In a previous lab (Improving code quality with SonarQube), we went through the process of installing Docker but it was mainly to run SonarQube inside of a container.Now we will be installing Docker on the same EC2 instance Jenkins is running on with the goal of integrating it into the pipeline.. For me to be able to do this, I had to change the EC2 instance ...\", 'https://reintech.io/blog/containerization-docker-azure-devops': \"This integration provides a robust environment for automating the continuous integration and deployment (CI/CD) pipeline, resulting in efficient and scalable workflows. Understanding Docker in Azure DevOps. Docker utilizes containers to encapsulate an application's code, libraries, and dependencies into a single object.\", 'https://learn.microsoft.com/en-us/azure/devops/pipelines/ecosystems/containers/build-image?view=azure-devops': 'Build a Linux or Windows image. Sign in to your Azure DevOps organization, and go to your project. Go to Pipelines, and select New Pipeline or Create Pipeline if creating the first pipeline in the project. Select GitHub as the location for your source code. Select your repository, and then select Starter pipeline.', 'https://dev.to/docker/automated-updates-made-easy-unveiling-docker-compose-file-watch-4jgc': 'How Docker Compose File Watch Addresses the Developer Problem: Docker Compose File Watch emerges as a beacon of hope for developers grappling with the complexities of manual container updates. At its core, this experimental feature embodies the principle of automation - the art of simplifying and streamlining tasks that were once labor-intensive.', 'https://blog.devgenius.io/docker-compose-complete-guide-with-hands-on-examples-c5697ec84220': 'To make a new file called docker-compose.yml for your project, head to the root of your project folder. This file will be used to manage the frontend and backend services of your project. Before, we had to manually enter the following commands to. Create a network: docker network create hitc-network.', 'https://reintech.io/blog/using-docker-compose-continuous-deployment-pipelines': \"To integrate Docker Compose into your CD pipeline, you'll typically follow these steps: Create a Docker Compose file for your application. Set up a Continuous Integration (CI) server to monitor your repository for changes. Configure the CI server to use Docker Compose to build and test your application. Configure the CI server to deploy your ...\", 'https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179': 'docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...', 'https://www.appsdeveloperblog.com/scaling-with-docker-compose-a-beginners-guide/': 'The first step is to define our services in a docker-compose.yml file. This file will contain the configurations of our Tomcat and MySQL services. Here\\'s a simple configuration: In this file, we have two services: \"db\" and \"web\". The \"db\" service uses the official MySQL 5.7 image from Docker Hub.', 'https://www.docker.com/blog/scaling-docker-compose-up/': \"Scaling Docker Compose Up. Milas Bowman. Docker Compose 's simplicity  just run compose up  has been an integral part of developer workflows for a decade, with the first commit occurring in 2013, back when it was called Plum. Although the feature set has grown dramatically in that time, maintaining that experience has always been ...\", 'https://dev.to/tellaboutcrypt/revolutionizing-application-deployment-and-scalability-using-docker-1mee': 'Scaling applications with Docker Swarm mode. Scaling applications using Docker Swarm and achieving a high level of availability and scalability involves proper deployment and management of a cluster of Docker nodes. Docker nodes are essentially a swarm created in swarm mode. These nodes in a swarm act as a single entity.', 'https://reintech.io/blog/scaling-services-docker-compose': \"Scaling Up Services. docker-compose up --scale service_name=num_instances -d. This command increases the number of containers running for 'service_name' to 'num_instances'. The '-d' flag detaches and runs containers in the background. It's essential to ensure that your services are stateless or that their state is externalized for this to work ...\"}\n",
      "2024-04-21 17:32:52,766 [MainThread  ] [INFO ]  Dumped 7574 characters for [Bob] - \n",
      "\t {\"https://blog.devops.dev/a-deep-dive-into-docker-compose-for-devops-engineers-5b640bc47715\": \"Docker Compose is a tool that makes it easier to manage the complexities of multi-container applications. Instead of managing each Docker container individually, Docker Compose allows you to define multiple containers, their configurations, networks, and volumes in a single docker-compose.yml file. With a single command, you can spin up or tear ...\", \"https://blog.devops.dev/devops-zero-to-hero-5-docker-compose-to-run-multi-container-docker-applications-f8e51db47f22\": \"mkdir docker-compose cd docker-compose touch docker-compose.yml requirements.txt app.py Dockerfile mkdir -p static/css touch static/css/style.css mkdir templates touch templates/index.html. Dockerfile \\u2014 This will be used to build the web application image. app.py \\u2014 This will contain the Flask code for the web application we will build in ...\", \"https://reintech.io/blog/continuous-integration-workflows-docker-compose\": \"In the world of software development, Continuous Integration (CI) has become an indispensable practice, allowing teams to merge their code changes into a central repository, where builds and tests are run automatically. This approach minimizes integration issues and leads to more reliable software. Docker Compose is a tool that can significantly simplify the CI process by defining and running ...\", \"https://medium.com/@daithimassey/how-to-set-up-a-devops-pipeline-from-scratch-a-comprehensive-guide-308763205462\": \"Initialize a New Repository. Clone an Existing Repository. Basic Git Workflow. Here's a simplified workflow to give you an idea of how to work with Git: 1. Create a New Branch: Always create a ...\", \"https://blogbells.com/containerization/using-docker-in-ci-cd-how-to-improve-your-devops-pipeline/\": \"Implementation Steps: Docker in a CI/CD Pipeline. Integrating Docker into your CI/CD pipeline can be achieved with the following steps. Step 1: Define your Docker Image. The first step involves defining your Docker image. This is usually done in a Dockerfile, which specifies the base image, application code, and any dependencies your ...\", \"https://stackoverflow.com/questions/76349895/how-properly-run-and-use-docker-in-azure-devops-pipelines\": \"0. Below are the steps to execute a command on the docker image. Step 1: Create a service connection to the container registry if it is private. For public registries, a service connection is not required. Step 2: Specify the container in the resources section of the pipeline and add the service connection name as the endpoint as shown below.\", \"https://towardsdev.com/devops-lab-10-executing-docker-deployments-via-azure-devops-166b212b5dc8\": \"Docker pipeline tasks: Head back to the pipeline as we are going to add 2 more tasks. Search for docker and install both Docker and Docker CLI installer. Now we have to configure the Docker task. Click on the task then on Manage. Click on New service connection and select Docker Registry.\", \"https://towardsaws.com/devops-lab-7-automating-pipeline-deployments-with-docker-b3c02ba1bccf\": \"Let's start by installing Docker.In a previous lab (Improving code quality with SonarQube), we went through the process of installing Docker but it was mainly to run SonarQube inside of a container.Now we will be installing Docker on the same EC2 instance Jenkins is running on with the goal of integrating it into the pipeline.. For me to be able to do this, I had to change the EC2 instance ...\", \"https://reintech.io/blog/containerization-docker-azure-devops\": \"This integration provides a robust environment for automating the continuous integration and deployment (CI/CD) pipeline, resulting in efficient and scalable workflows. Understanding Docker in Azure DevOps. Docker utilizes containers to encapsulate an application's code, libraries, and dependencies into a single object.\", \"https://learn.microsoft.com/en-us/azure/devops/pipelines/ecosystems/containers/build-image?view=azure-devops\": \"Build a Linux or Windows image. Sign in to your Azure DevOps organization, and go to your project. Go to Pipelines, and select New Pipeline or Create Pipeline if creating the first pipeline in the project. Select GitHub as the location for your source code. Select your repository, and then select Starter pipeline.\", \"https://dev.to/docker/automated-updates-made-easy-unveiling-docker-compose-file-watch-4jgc\": \"How Docker Compose File Watch Addresses the Developer Problem: Docker Compose File Watch emerges as a beacon of hope for developers grappling with the complexities of manual container updates. At its core, this experimental feature embodies the principle of automation - the art of simplifying and streamlining tasks that were once labor-intensive.\", \"https://blog.devgenius.io/docker-compose-complete-guide-with-hands-on-examples-c5697ec84220\": \"To make a new file called docker-compose.yml for your project, head to the root of your project folder. This file will be used to manage the frontend and backend services of your project. Before, we had to manually enter the following commands to. Create a network: docker network create hitc-network.\", \"https://reintech.io/blog/using-docker-compose-continuous-deployment-pipelines\": \"To integrate Docker Compose into your CD pipeline, you'll typically follow these steps: Create a Docker Compose file for your application. Set up a Continuous Integration (CI) server to monitor your repository for changes. Configure the CI server to use Docker Compose to build and test your application. Configure the CI server to deploy your ...\", \"https://medium.com/@dtadmin/docking-your-workflow-a-hands-on-guide-to-docker-compose-installation-and-examples-898fd814e179\": \"docker-compose build =Look for all services containing the build. docker-compose run=Run a one-time command against a service. docker-compose up=Command used to start all the services of the ...\", \"https://www.appsdeveloperblog.com/scaling-with-docker-compose-a-beginners-guide/\": \"The first step is to define our services in a docker-compose.yml file. This file will contain the configurations of our Tomcat and MySQL services. Here's a simple configuration: In this file, we have two services: \\\"db\\\" and \\\"web\\\". The \\\"db\\\" service uses the official MySQL 5.7 image from Docker Hub.\", \"https://www.docker.com/blog/scaling-docker-compose-up/\": \"Scaling Docker Compose Up. Milas Bowman. Docker Compose 's simplicity \\u2014 just run compose up \\u2014 has been an integral part of developer workflows for a decade, with the first commit occurring in 2013, back when it was called Plum. Although the feature set has grown dramatically in that time, maintaining that experience has always been ...\", \"https://dev.to/tellaboutcrypt/revolutionizing-application-deployment-and-scalability-using-docker-1mee\": \"Scaling applications with Docker Swarm mode. Scaling applications using Docker Swarm and achieving a high level of availability and scalability involves proper deployment and management of a cluster of Docker nodes. Docker nodes are essentially a swarm created in swarm mode. These nodes in a swarm act as a single entity.\", \"https://reintech.io/blog/scaling-services-docker-compose\": \"Scaling Up Services. docker-compose up --scale service_name=num_instances -d. This command increases the number of containers running for 'service_name' to 'num_instances'. The '-d' flag detaches and runs containers in the background. It's essential to ensure that your services are stateless or that their state is externalized for this to work ...\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got search engine results: 5 for [how to ensure scalability in software development using Docker compose]\n"
     ]
    }
   ],
   "source": [
    "i = Interviews(topic=example_topic, interview_config=interview_config)\n",
    "\n",
    "g = StormGraph(interview_config=interview_config, topic=example_topic)\n",
    "g1 = await g.graph.ainvoke(i.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f257d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec50c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2fbdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857abf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = outline.invoke(t1)\n",
    "o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79bb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = expand_chain.invoke(t1)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429463f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = gen_perspectives_chain.invoke({\"examples\": r1.topics, \"topic\": example_topic})\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_chain_question_generator(fast_llm)\n",
    "t2 = {\"persona\": \"\"}\n",
    "\n",
    "q1 = c.invoke(t2)\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6716f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_in = {\"messages\": [HumanMessage(content=q1.content, name=\"JohnSmith\")]}\n",
    "a1 = await gen_queries_chain.ainvoke(q_in)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06904c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f625d9f8",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cade58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Question node \n",
    "\n",
    "# Test \n",
    "\n",
    "state = InterviewState(\n",
    "    interview_config=interview_config,\n",
    "    editor=Editor(affiliation=\"Example University\", name=\"John Doe\", role=\"Lead Editor\", description=\"Experienced in the field of biology.\"),\n",
    "    messages=[],\n",
    "    references={}\n",
    ")\n",
    "\n",
    "q2 = await node_generate_question.ainvoke(state)\n",
    "q2x = InterviewState.from_dict(q2)\n",
    "q2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a304fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = await node_generate_answer.ainvoke(q2x)\n",
    "q3x = InterviewState.from_dict(q3)\n",
    "q3x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81429d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_route_messages(q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112adea",
   "metadata": {},
   "source": [
    "# Main Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Interviews(topic=example_topic, interview_config=interview_config)\n",
    "i1 = await node_survey_subjects.ainvoke(i)\n",
    "\n",
    "i1x = Interviews.from_dict(i1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bcf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Interviews(topic=example_topic, interview_config=interview_config)\n",
    "\n",
    "g = StormGraph(interview_config=interview_config, topic=example_topic)\n",
    "await g.graph.ainvoke(i.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63098a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interview_graph = StormInterviewGraph1(interview_config=interview_config)\n",
    "\n",
    "# Generate perspectives\n",
    "perspectives = await survey_subjects.ainvoke(example_topic)\n",
    "\n",
    "# Set perspectives\n",
    "interview_graph.interviews.perspectives = perspectives\n",
    "interview_graph.initialize_conversations()\n",
    "logger.info(interview_graph.interviews.conversations.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interview\n",
    "\n",
    "final_step = None\n",
    "# await interview_graph.stream_and_return_results(\n",
    "#     {\"editor\": perspectives.editors[0], \"messages\": []}\n",
    "# )\n",
    "\n",
    "initial_state : InterviewState = InterviewState(interview_config=interview_config, editor=p1.editors[0], messages=[], references={})\n",
    "# {\n",
    "#     \"editor\": p1.editors[0],\n",
    "#     \"messages\": [\n",
    "#         AIMessage(\n",
    "#             content=f\"So you said you were writing an article on {example_topic}?\",\n",
    "#             name=\"SubjectMatterExpert\",\n",
    "#         )\n",
    "#     ],\n",
    "# }\n",
    "async for step in interview_graph.graph.astream(initial_state.as_dict()):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(f\"Processing step: {name}\")\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "    if END in step:\n",
    "        final_step = step\n",
    "        \n",
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state = next(iter(step.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "state2 = InterviewState.from_dict(final_state)\n",
    "state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b02cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state2.trim_messages(max_characters=1000)\n",
    "# final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244c235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bad132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca82998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e9c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ef45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88d122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b278d8c-9e34-42ab-9649-bc7b3570bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Generate Initial Outline\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a Wikipedia writer. Write an outline for a Wikipedia page about a user-provided topic. Be comprehensive and specific.\",\n",
    "        ),\n",
    "        (\"user\", \"{topic}\\n{format_instructions}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    description: str = Field(..., title=\"Content of the subsection\")\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.description}\".strip()\n",
    "\n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    description: str = Field(..., title=\"Content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"### {subsection.subsection_title}\\n\\n{subsection.description}\"\n",
    "            for subsection in self.subsections or []\n",
    "        )\n",
    "        return f\"## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the Wikipedia page\")\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and descriptions for each section of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
    "\n",
    "\n",
    "outline_parser = PydanticOutputParser(pydantic_object=Outline)\n",
    "\n",
    "generate_outline_direct = direct_gen_outline_prompt.partial(format_instructions=outline_parser.get_format_instructions()) | fast_llm | outline_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee8329-896b-4085-a1fa-fec0a15937ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_topic = \"Impact of million-plus token context window language models on RAG\"\n",
    "\n",
    "initial_outline = generate_outline_direct.invoke({\"topic\": example_topic})\n",
    "\n",
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c37266-d5d5-4fbb-831f-8f809e966236",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expand Topics\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f63ad0-7e07-48ac-85a9-80a53b528c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"I'm writing a Wikipedia page for a topic mentioned below. Please identify and recommend some Wikipedia pages on closely related subjects. I'm looking for examples that provide insights into interesting aspects commonly associated with this topic, or examples that help me understand the typical content and structure included in Wikipedia pages for similar topics.\n",
    "\n",
    "Please list the as many subjects and urls as you can.\n",
    "\n",
    "Topic of interest: {topic}\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Comprehensive list of related subjects as background research.\",\n",
    "    )\n",
    "\n",
    "\n",
    "related_topics_parser = PydanticOutputParser(pydantic_object=RelatedSubjects)\n",
    "\n",
    "expand_chain = gen_related_topics_prompt.partial(format_instructions=related_topics_parser.get_format_instructions()) | fast_llm | related_topics_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f801936-f6f7-44a0-bc79-4f0132fba79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_subjects = await expand_chain.ainvoke({\"topic\": example_topic})\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc42a4-45f1-470c-a3f6-20a5661d5b43",
   "metadata": {},
   "source": [
    "## Generate Perspectives\n",
    "\n",
    "From these related subjects, we can select representative Wikipedia editors as \"subject matter experts\" with distinct backgrounds and affiliations. These will help distribute the search process to encourage a more well-rounded final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ea824-c561-4949-bbd4-127281f3eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Editor(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description=\"Primary affiliation of the editor.\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the editor.\",\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the editor in the context of the topic.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Description of the editor's focus, concerns, and motives.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    editors: List[Editor] = Field(\n",
    "        description=\"Comprehensive list of editors with their roles and affiliations.\",\n",
    "        # Add a pydantic validation/restriction to be at most M editors\n",
    "    )\n",
    "\n",
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You need to select a diverse (and distinct) group of Wikipedia editors who will work together to create a comprehensive article on the topic. Each of them represents a different perspective, role, or affiliation related to this topic.\\\n",
    "    You can use other Wikipedia pages of related topics for inspiration. For each editor, add a description of what they will focus on.\n",
    "\n",
    "    Wiki page outlines of related topics for inspiration:\n",
    "    {examples}\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"Topic of interest: {topic}\\n\\n{format_instructions}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "perspectives_parser = PydanticOutputParser(pydantic_object=Perspectives)\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt.partial(format_instructions=perspectives_parser.get_format_instructions()) | fast_llm | perspectives_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a87f7-a867-42f7-ac98-da7ce1110daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda, chain as as_runnable\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
    "\n",
    "\n",
    "def format_doc(doc, max_length=1000)-> str:\n",
    "    related = \"- \".join(doc.metadata[\"categories\"])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\n\\nRelated\\n{related}\"[\n",
    "        :max_length\n",
    "    ]\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def survey_subjects(topic: str)-> Perspectives:\n",
    "    print(f\"Survey Subjects for Topic: {topic}\")\n",
    "    related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(\n",
    "        related_subjects.topics, return_exceptions=True\n",
    "    )\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "    print(f\"Retrieved {len(all_docs)} docs for Topic: {topic}\")\n",
    "    \n",
    "    formatted = format_docs(all_docs)\n",
    "    return await gen_perspectives_chain.ainvoke({\"examples\": formatted, \"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2b5eb-46cb-410f-8b15-6fc8ead58382",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = await survey_subjects.ainvoke(example_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90dd94-b215-4a5d-83b2-498e969ff7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perspectives.dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abdf40-80dc-434c-8116-d6b9cbde5572",
   "metadata": {},
   "source": [
    "## Expert Dialog\n",
    "\n",
    "Each wikipedia writer is primed to role-play using the perspectives presented above. It will ask a series of questions of a second \"domain expert\" with access to a search engine. This generate content to generate a refined outline as well as an updated index of reference documents.\n",
    "\n",
    "### Interview State\n",
    "\n",
    "The conversation is cyclic, so we will construct it within its own graph. The State will contain messages, the reference docs, and the editor (with its own \"persona\") to make it easy to parallelize these conversations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fa250-8b81-465b-ba06-fe7b33e4d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "\n",
    "def add_messages(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    return left + right\n",
    "\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    # Can only set at the outset\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0639d2-e8a6-43d4-8e9a-eb5f4051578c",
   "metadata": {},
   "source": [
    "# Dialog Roles\n",
    "\n",
    "The graph will have two participants: the wikipedia editor (generate_question), who asks questions based on its assigned role, and a domain expert (`gen_answer_chain), who uses a search engine to answer the questions as accurately as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644c46c-4d23-49e1-9093-39b4f6c8c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an experienced Wikipedia writer and want to edit a specific page. \\\n",
    "Besides your identity as a Wikipedia writer, you have a specific focus when researching the topic. \\\n",
    "Now, you are chatting with an expert to get information. Ask good questions to get more useful information.\n",
    "\n",
    "When you have no more questions to ask, say \"Thank you so much for your help!\" to end the conversation.\\\n",
    "Please only ask one question at a time and don't ask what you have asked before.\\\n",
    "Your questions should be related to the topic you want to write.\n",
    "Be comprehensive and curious, gaining as much unique insight from the expert as possible.\\\n",
    "\n",
    "Stay true to your specific perspective:\n",
    "\n",
    "{persona}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def tag_with_name(ai_message: AIMessage, name: str) -> AIMessage:\n",
    "    ai_message.name = name\n",
    "    return ai_message\n",
    "\n",
    "\n",
    "def swap_roles(state: InterviewState, name: str) -> InterviewState:\n",
    "\n",
    "    # Normalize name\n",
    "    name = cleanup_name(name)\n",
    "\n",
    "    print(f'Swapping roles for {name}')\n",
    "\n",
    "    converted = []\n",
    "    for message in state[\"messages\"]:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
    "        converted.append(message)\n",
    "    \n",
    "    print(f'Converted messages for {name} while swapping roles: {len(converted)} messages')\n",
    "\n",
    "    return {\"messages\": converted}\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def generate_question(state: InterviewState) -> InterviewState:\n",
    "    editor = state[\"editor\"]\n",
    "\n",
    "    name = cleanup_name(editor.name)\n",
    "\n",
    "    print(f'Generating question for {name}')\n",
    "\n",
    "    gn_chain = (\n",
    "        RunnableLambda(swap_roles).bind(name=name)\n",
    "        | gen_qn_prompt.partial(persona=editor.persona)\n",
    "        | fast_llm\n",
    "        | RunnableLambda(tag_with_name).bind(name=name)\n",
    "    )\n",
    "    result:AIMessage = await gn_chain.ainvoke(state)\n",
    "\n",
    "    print(f'Generated question for {name}')\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac2384-a123-467f-bbc6-828be9dc04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(f\"So you said you were writing an article on {example_topic}?\")\n",
    "]\n",
    "question = await generate_question.ainvoke(\n",
    "    {\n",
    "        \"editor\": perspectives.editors[0],\n",
    "        \"messages\": messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "question[\"messages\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e50f7-4e2c-4307-853d-2fc8f0b3dd82",
   "metadata": {},
   "source": [
    "### Answer questions\n",
    "\n",
    "The `gen_answer_chain` first generates queries (query expansion) to answer the editor's question, then responds with citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa969e-920f-487e-b124-6495777a1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        description=\"Comprehensive list of search engine queries to answer the user's questions.\",\n",
    "    )\n",
    "\n",
    "\n",
    "gen_queries_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful research assistant. Query the search engine to answer the user's questions.\\n{format_instructions}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "queries_parser = PydanticOutputParser(pydantic_object=Queries)\n",
    "\n",
    "gen_queries_chain = gen_queries_prompt.partial(format_instructions=queries_parser.get_format_instructions()) | fast_llm | queries_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25baa82-da8e-41ec-b4e0-8a24c7cf737d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "queries = await gen_queries_chain.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22273c9a-a505-40c3-bd6b-70f74393a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AnswerWithCitations(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"Comprehensive answer to the user's question with citations.\",\n",
    "    )\n",
    "    cited_urls: List[str] = Field(\n",
    "        description=\"List of urls cited in the answer.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.answer}\\n\\nCitations:\\n\\n\" + \"\\n\".join(\n",
    "            f\"[{i+1}]: {url}\" for i, url in enumerate(self.cited_urls)\n",
    "        )\n",
    "\n",
    "\n",
    "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert who can use information effectively. You are chatting with a Wikipedia writer who wants\\\n",
    " to write a Wikipedia page on the topic you know. You have gathered the related information and will now use the information to form a response.\n",
    "\n",
    "Make your response as informative as possible and make sure every sentence is supported by the gathered information.\n",
    "Each response must be backed up by a citation from a reliable source, formatted as a footnote, reproducing the URLS after your response.\n",
    "{format_instructions}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ac_parser = PydanticOutputParser(pydantic_object=AnswerWithCitations)\n",
    "\n",
    "gen_answer_chain = gen_answer_prompt.partial(format_instructions=ac_parser.get_format_instructions()) | fast_llm | ac_parser \n",
    "\n",
    "# .with_structured_output(\n",
    "#     AnswerWithCitations, include_raw=True\n",
    "# ).with_config(run_name=\"GenerateAnswer\")\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39c4f4-f2ca-4504-84f9-ff1a86b01d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# DDG \n",
    "search_engine = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "@tool\n",
    "async def search_engine(query: str):\n",
    "    \"\"\"Search engine to the internet.\"\"\"\n",
    "\n",
    "    print(f\"Searching DuckDuckGo for [{query}]\")\n",
    "\n",
    "    results = DuckDuckGoSearchAPIWrapper()._ddgs_text(query)\n",
    "\n",
    "    print(f\"Got search engine results: {len(results)} for [{query}]\")\n",
    "    \n",
    "    return [{\"content\": r[\"body\"], \"url\": r[\"href\"]} for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74edcc-a272-4ec1-92fc-756bf0690e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "import json, re\n",
    "\n",
    "\n",
    "async def gen_answer(\n",
    "    state: InterviewState,\n",
    "    config: Optional[RunnableConfig] = None,\n",
    "    name: str = \"SubjectMatterExpert\",\n",
    "    max_str_len: int = 15000,\n",
    "):\n",
    "    name = cleanup_name(name)\n",
    "\n",
    "    print(f'Generating answers for [{name}]')\n",
    "\n",
    "\n",
    "    swapped_state = swap_roles(state, name)  # Convert all other AI messages\n",
    "    \n",
    "    queries:Queries = await gen_queries_chain.ainvoke(swapped_state)\n",
    "\n",
    "    print(f\"Got {len(queries.queries)} search engine queries for [{name}]\")\n",
    "\n",
    "    query_results = await search_engine.abatch(\n",
    "        queries.queries, config, return_exceptions=True\n",
    "    )\n",
    "    successful_results = [\n",
    "        res for res in query_results if not isinstance(res, Exception)\n",
    "    ]\n",
    "\n",
    "    print(f\"Got {len(successful_results)} search engine results for [{name}]\")\n",
    "\n",
    "    all_query_results = {\n",
    "        res[\"url\"]: res[\"content\"] for results in successful_results for res in results\n",
    "    }\n",
    "\n",
    "    # We could be more precise about handling max token length if we wanted to here\n",
    "    dumped = json.dumps(all_query_results)[:max_str_len]\n",
    "    \n",
    "    ai_message: AIMessage = str(queries)\n",
    "    # print(f\"Got {ai_message} for [{name}]\")\n",
    "    \n",
    "    # tool_call = queries[\"raw\"].additional_kwargs[\"tool_calls\"][0]\n",
    "    # tool_id = tool_call[\"id\"]\n",
    "\n",
    "    # tool_message = ToolMessage(tool_call_id=tool_id, content=dumped)\n",
    "    tool_message = HumanMessage(content=dumped)\n",
    "\n",
    "    swapped_state[\"messages\"].extend([ai_message, tool_message])\n",
    "    \n",
    "    # Only update the shared state with the final answer to avoid\n",
    "    # polluting the dialogue history with intermediate messages\n",
    "    try:\n",
    "        generated: AnswerWithCitations = await gen_answer_chain.ainvoke(swapped_state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer for [{name}] - {e}\")\n",
    "        generated = AnswerWithCitations(answer=\"\", cited_urls=[])\n",
    "    \n",
    "    cited_urls = set(generated.cited_urls)\n",
    "    \n",
    "    # Save the retrieved information to a the shared state for future reference\n",
    "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
    "    \n",
    "    formatted_message = AIMessage(name=name, content=generated.as_str)\n",
    "\n",
    "    print(f'Finished generating answer for [{name}]')\n",
    "    return {\"messages\": [formatted_message], \"references\": cited_references}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934aafd6-7f0d-4a1b-8a52-45b89d8b3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_answer = await gen_answer(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "example_answer[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998671bf-958d-44c0-8421-523a71bea01a",
   "metadata": {},
   "source": [
    "# Construct the Interview Graph\n",
    "\n",
    "Now that we've defined the editor and domain expert, we can compose them in a graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800f958-00e0-4913-a246-c34dc3f0a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_turns = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "builder = StateGraph(InterviewState)\n",
    "\n",
    "builder.add_node(\"ask_question\", generate_question)\n",
    "builder.add_node(\"answer_question\", gen_answer)\n",
    "builder.add_conditional_edges(\"answer_question\", route_messages)\n",
    "builder.add_edge(\"ask_question\", \"answer_question\")\n",
    "\n",
    "builder.set_entry_point(\"ask_question\")\n",
    "interview_graph = builder.compile().with_config(run_name=\"Conduct Interviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c405fc-5b1c-44f5-b860-a10fe0d6616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# comment out if you have not installed pygraphviz\n",
    "# Image(interview_graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d47607-6c0b-493a-aebc-48356d0e0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_step = None\n",
    "\n",
    "initial_state = {\n",
    "    \"editor\": perspectives.editors[0],\n",
    "    \"messages\": [\n",
    "        AIMessage(\n",
    "            content=f\"So you said you were writing an article on {example_topic}?\",\n",
    "            name=\"SubjectMatterExpert\",\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "async for step in interview_graph.astream(initial_state):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(f\"Processing step: {name}\")\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "    if END in step:\n",
    "        final_step = step\n",
    "        \n",
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a97ec-09a1-4873-b559-275526971a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e14dcb",
   "metadata": {},
   "source": [
    "## Refine Outline\n",
    "\n",
    "At this point in STORM, we've conducted a large amount of research from different perspectives. It's time to refine the original outline based on these investigations. Below, create a chain using the LLM with a long context window to update the original outline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284eb72-3856-406d-8582-5a1c92fd292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a Wikipedia writer. You have gathered information from experts and search engines. Now, you are refining the outline of the Wikipedia page. \\\n",
    "You need to make sure that the outline is comprehensive and specific. \\\n",
    "Topic you are writing about: {topic} \n",
    "\n",
    "Old outline:\n",
    "\n",
    "{old_outline}\n",
    "\"\"\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Refine the outline based on your conversations with subject-matter experts:\\n\\nConversations:\\n\\n{conversations}\\n\\n{format_instructions}\\n\\nWrite the refined Wikipedia outline:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Using turbo preview since the context can get quite long\n",
    "refine_outline_chain = refine_outline_prompt.partial(format_instructions=outline_parser.get_format_instructions()) | long_context_llm | outline_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e58c5-086f-49ba-b921-791669d04b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_outline = refine_outline_chain.invoke(\n",
    "    {\n",
    "        \"topic\": example_topic,\n",
    "        \"old_outline\": initial_outline.as_str,\n",
    "        \"conversations\": \"\\n\\n\".join(\n",
    "            f\"### {m.name}\\n\\n{m.content}\" for m in final_state[\"messages\"]\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c397dc5-e614-4a7f-9f78-67dffc9b8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refined_outline.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "reference_docs = [\n",
    "    Document(page_content=v, metadata={\"source\": k})\n",
    "    for k, v in final_state[\"references\"].items()\n",
    "]\n",
    "\n",
    "print(f\"Number of references: {len(reference_docs)}\")\n",
    "\n",
    "# This really doesn't need to be a vectorstore for this size of data.\n",
    "# It could just be a numpy matrix. Or you could store documents\n",
    "# across requests if you want.\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    reference_docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05496dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"What's a long context LLM anyway?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708d31a",
   "metadata": {},
   "source": [
    "#### Generate Sections\n",
    "\n",
    "Now you can generate the sections using the indexed docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    content: str = Field(\n",
    "        ...,\n",
    "        title=\"Full content of the subsection. Include [#] citations to the cited sources where relevant.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.content}\".strip()\n",
    "\n",
    "\n",
    "class WikiSection(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    content: str = Field(..., title=\"Full content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "    citations: List[str] = Field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            subsection.as_str for subsection in self.subsections or []\n",
    "        )\n",
    "        citations = \"\\n\".join([f\" [{i}] {cit}\" for i, cit in enumerate(self.citations)])\n",
    "        return (\n",
    "            f\"## {self.section_title}\\n\\n{self.content}\\n\\n{subsections}\".strip()\n",
    "            + f\"\\n\\n{citations}\".strip()\n",
    "        )\n",
    "\n",
    "\n",
    "section_writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia writer. Complete your assigned WikiSection from the following outline:\\n\\n\"\n",
    "            \"{outline}\\n\\nCite your sources, using the following references:\\n\\n<Documents>\\n{docs}\\n<Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"Write the full WikiSection for the {section} section.\\n{format_instructions}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def retrieve(inputs: dict):\n",
    "    docs = await retriever.ainvoke(inputs[\"topic\"] + \": \" + inputs[\"section\"])\n",
    "    formatted = \"\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "    return {\"docs\": formatted, **inputs}\n",
    "\n",
    "wiki_parser = PydanticOutputParser(pydantic_object=WikiSection)\n",
    "\n",
    "section_writer = (\n",
    "    retrieve\n",
    "    | section_writer_prompt.partial(format_instructions=wiki_parser.get_format_instructions())\n",
    "    | long_context_llm\n",
    "    | wiki_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03723e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = await section_writer.ainvoke(\n",
    "    {\n",
    "        \"outline\": refined_outline.as_str,\n",
    "        \"section\": refined_outline.sections[1].section_title,\n",
    "        \"topic\": example_topic,\n",
    "    }\n",
    ")\n",
    "print(section.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd728d",
   "metadata": {},
   "source": [
    "#### Generate final article\n",
    "\n",
    "Now we can rewrite the draft to appropriately group all the citations and maintain a consistent voice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05089f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia author. Write the complete wiki article on {topic} using the following section drafts:\\n\\n\"\n",
    "            \"{draft}\\n\\nStrictly follow Wikipedia format guidelines.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            'Write the complete Wiki article using markdown format. Organize citations using footnotes like \"[1]\",\"\" avoiding duplicates in the footer. Include URLs in the footer.',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | long_context_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in writer.stream({\"topic\": example_topic, \"draft\": section.as_str}):\n",
    "    print(tok, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ab734",
   "metadata": {},
   "source": [
    "## Final Flow\n",
    "\n",
    "Now it's time to string everything together. We will have 6 main stages in sequence:\n",
    ".\n",
    "\n",
    "1. Generate the initial outline + perspectives\n",
    "2. Batch converse with each perspective to expand the content for the article\n",
    "3. Refine the outline based on the conversations\n",
    "4. Index the reference docs from the conversations\n",
    "5. Write the individual sections of the article\n",
    "6. Write the final wiki\n",
    "\n",
    "The state tracks the outputs of each stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    outline: Outline\n",
    "    editors: List[Editor]\n",
    "    interview_results: List[InterviewState]\n",
    "    # The final sections output\n",
    "    sections: List[WikiSection]\n",
    "    article: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def initialize_research(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    coros = (\n",
    "        generate_outline_direct.ainvoke({\"topic\": topic}),\n",
    "        survey_subjects.ainvoke(topic),\n",
    "    )\n",
    "    results = await asyncio.gather(*coros)\n",
    "    return {\n",
    "        **state,\n",
    "        \"outline\": results[0],\n",
    "        \"editors\": results[1].editors,\n",
    "    }\n",
    "\n",
    "\n",
    "async def conduct_interviews(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    initial_states = [\n",
    "        {\n",
    "            \"editor\": editor,\n",
    "            \"messages\": [\n",
    "                AIMessage(\n",
    "                    content=f\"So you said you were writing an article on {topic}?\",\n",
    "                    name=\"SubjectMatterExpert\",\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "        for editor in state[\"editors\"]\n",
    "    ]\n",
    "    # We call in to the sub-graph here to parallelize the interviews\n",
    "    interview_results = await interview_graph.abatch(initial_states)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"interview_results\": interview_results,\n",
    "    }\n",
    "\n",
    "\n",
    "def format_conversation(interview_state):\n",
    "    messages = interview_state[\"messages\"]\n",
    "    convo = \"\\n\".join(f\"{m.name}: {m.content}\" for m in messages)\n",
    "    return f'Conversation with {interview_state[\"editor\"].name}\\n\\n' + convo\n",
    "\n",
    "\n",
    "async def refine_outline(state: ResearchState):\n",
    "    convos = \"\\n\\n\".join(\n",
    "        [\n",
    "            format_conversation(interview_state)\n",
    "            for interview_state in state[\"interview_results\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    updated_outline = await refine_outline_chain.ainvoke(\n",
    "        {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"old_outline\": state[\"outline\"].as_str,\n",
    "            \"conversations\": convos,\n",
    "        }\n",
    "    )\n",
    "    return {**state, \"outline\": updated_outline}\n",
    "\n",
    "\n",
    "async def index_references(state: ResearchState):\n",
    "    all_docs = []\n",
    "    for interview_state in state[\"interview_results\"]:\n",
    "        reference_docs = [\n",
    "            Document(page_content=v, metadata={\"source\": k})\n",
    "            for k, v in interview_state[\"references\"].items()\n",
    "        ]\n",
    "        all_docs.extend(reference_docs)\n",
    "    await vectorstore.aadd_documents(all_docs)\n",
    "    return state\n",
    "\n",
    "\n",
    "async def write_sections(state: ResearchState):\n",
    "    outline = state[\"outline\"]\n",
    "    sections = await section_writer.abatch(\n",
    "        [\n",
    "            {\n",
    "                \"outline\": refined_outline.as_str,\n",
    "                \"section\": section.section_title,\n",
    "                \"topic\": state[\"topic\"],\n",
    "            }\n",
    "            for section in outline.sections\n",
    "        ]\n",
    "    )\n",
    "    return {\n",
    "        **state,\n",
    "        \"sections\": sections,\n",
    "    }\n",
    "\n",
    "\n",
    "async def write_article(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state[\"sections\"]\n",
    "    draft = \"\\n\\n\".join([section.as_str for section in sections])\n",
    "    article = await writer.ainvoke({\"topic\": topic, \"draft\": draft})\n",
    "    return {\n",
    "        **state,\n",
    "        \"article\": article,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87881e3",
   "metadata": {},
   "source": [
    "#### Create the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_of_storm = StateGraph(ResearchState)\n",
    "\n",
    "nodes = [\n",
    "    (\"init_research\", initialize_research),\n",
    "    (\"conduct_interviews\", conduct_interviews),\n",
    "    (\"refine_outline\", refine_outline),\n",
    "    (\"index_references\", index_references),\n",
    "    (\"write_sections\", write_sections),\n",
    "    (\"write_article\", write_article),\n",
    "]\n",
    "for i in range(len(nodes)):\n",
    "    name, node = nodes[i]\n",
    "    builder_of_storm.add_node(name, node)\n",
    "    if i > 0:\n",
    "        builder_of_storm.add_edge(nodes[i - 1][0], name)\n",
    "\n",
    "builder_of_storm.set_entry_point(nodes[0][0])\n",
    "builder_of_storm.set_finish_point(nodes[-1][0])\n",
    "storm = builder_of_storm.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a815f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for step in storm.astream(\n",
    "    {\n",
    "        \"topic\": \"Building better slack bots using LLMs\",\n",
    "    }\n",
    "):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name])[:300])\n",
    "    if END in step:\n",
    "        results = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = results[END][\"article\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b094067",
   "metadata": {},
   "source": [
    "## Render the Wiki\n",
    "\n",
    "Now we can render the final wiki page!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7750c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# We will down-header the sections to create less confusion in this notebook\n",
    "Markdown(article.replace(\"\\n#\", \"\\n##\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e24611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
